{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data from image folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, itertools, random, imageio, sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "faces_folder = \"faces\"\n",
    "image_size = 128\n",
    "num_labels = 2\n",
    "pixel_depth = 255.0\n",
    "\n",
    "def get_subdirs(a_dir):\n",
    "  return [name for name in os.listdir(a_dir) \n",
    "          if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "def get_files(a_dir):\n",
    "  return [os.path.join(a_dir, name) for name in os.listdir(a_dir) \n",
    "          if os.path.isfile(os.path.join(a_dir, name)) and name != \".DS_Store\"]\n",
    "\n",
    "def same_person_combinations():\n",
    "  combinations = []\n",
    "  people_dirs = get_subdirs(faces_folder)\n",
    "  for people_dir in people_dirs:\n",
    "    people_path = faces_folder + \"/\" + people_dir\n",
    "    files_for_person = get_files(people_path)\n",
    "    same_person_all_combinations = list(itertools.permutations(files_for_person, 2))\n",
    "    combinations.append(same_person_all_combinations)\n",
    "  return combinations\n",
    "\n",
    "def different_people_combinations(unique_people, cap_at):\n",
    "  different_people_combinations = list(itertools.permutations(unique_people, 2))\n",
    "  random.shuffle(different_people_combinations)\n",
    "  return different_people_combinations[:cap_at]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done same person\n"
     ]
    }
   ],
   "source": [
    "people_combinations = same_person_combinations()\n",
    "\n",
    "same_person_count = 0\n",
    "for person in people_combinations:\n",
    "  for person_combination in person:\n",
    "    same_person_count += 1\n",
    "    \n",
    "dataset = np.ndarray(shape=(same_person_count * 2, image_size * image_size * 2), dtype=np.float32)\n",
    "labels = np.ndarray(shape=(same_person_count * 2, 2), dtype=np.float32)\n",
    "\n",
    "unique_people = []\n",
    "\n",
    "i = 0\n",
    "for person in people_combinations:\n",
    "  chose_one_from_this_person = False\n",
    "  for person_combination in person:\n",
    "    img_1 = person_combination[0]\n",
    "    img_2 = person_combination[1]\n",
    "    try:\n",
    "      image_data_1 = (imageio.imread(img_1).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "      image_data_2 = (imageio.imread(img_1).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "      if image_data_1.shape != (image_size, image_size) or image_data_2.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      else:\n",
    "        img_1_flattened = image_data_1.reshape(image_size * image_size)\n",
    "        img_2_flattened = image_data_2.reshape(image_size * image_size)\n",
    "        dataset[i] = np.concatenate((img_1_flattened, img_2_flattened), axis=0)\n",
    "        labels[i] = np.array([1, 0]) # same person\n",
    "        i += 1\n",
    "        \n",
    "        if not chose_one_from_this_person:\n",
    "          unique_people.append(img_1)\n",
    "          chose_one_from_this_person = True\n",
    "    except (IOError, ValueError) as e:\n",
    "      print(\"skipping\")\n",
    "      \n",
    "print(\"Done same person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done different people\n"
     ]
    }
   ],
   "source": [
    "# get as many different people as the same person count\n",
    "different_people_combinations = different_people_combinations(unique_people, same_person_count)\n",
    "\n",
    "for dperson in different_people_combinations:\n",
    "  img_1 = dperson[0]\n",
    "  img_2 = dperson[1]\n",
    "  try:\n",
    "    image_data_1 = (imageio.imread(img_1).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "    image_data_2 = (imageio.imread(img_1).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "    if image_data_1.shape != (image_size, image_size) or image_data_2.shape != (image_size, image_size):\n",
    "      raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "    else:\n",
    "      img_1_flattened = image_data_1.reshape(image_size * image_size)\n",
    "      img_2_flattened = image_data_2.reshape(image_size * image_size)\n",
    "      dataset[i] = np.concatenate((img_1_flattened, img_2_flattened), axis=0)\n",
    "      labels[i] = np.array([0, 1]) # different person\n",
    "      i += 1\n",
    "  except (IOError, ValueError) as e:\n",
    "      print(\"skipping\")\n",
    "      \n",
    "print(\"Done different people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data [ 0.2254902   0.23333333  0.24509804 ... -0.26862746 -0.26862746\n",
      " -0.2647059 ] label [1. 0.]\n",
      "dataset (25564, 32768)\n",
      "labels (25564, 2)\n"
     ]
    }
   ],
   "source": [
    "# shuffle labels and dataset in unison.\n",
    "dataset, labels = sklearn.utils.shuffle(dataset, labels)\n",
    "print(\"data\", dataset[0], \"label\", labels[0])\n",
    "print(\"dataset\", dataset.shape)\n",
    "print(\"labels\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (23014, 32768) (23014, 2)\n",
      "valid (1275, 32768) (1275, 2)\n",
      "test (1275, 32768) (1275, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 23014\n",
    "valid_size = 1275\n",
    "test_size = 1275\n",
    "\n",
    "pickle_file = \"faces.pickle\"\n",
    "\n",
    "try:\n",
    "  save = {\n",
    "    'train_dataset': dataset[:train_size],\n",
    "    'train_labels': labels[:train_size],\n",
    "    'valid_dataset': dataset[train_size:(train_size + valid_size)],\n",
    "    'valid_labels': labels[train_size:(train_size + valid_size)],\n",
    "    'test_dataset': dataset[(train_size + valid_size):],\n",
    "    'test_labels': labels[(train_size + valid_size):],\n",
    "    }\n",
    "  print(\"train\", save[\"train_dataset\"].shape, save[\"train_labels\"].shape)\n",
    "  print(\"valid\", save[\"valid_dataset\"].shape, save[\"valid_labels\"].shape)\n",
    "  print(\"test\", save[\"test_dataset\"].shape, save[\"test_labels\"].shape)\n",
    "  \n",
    "  n_bytes = 2**31\n",
    "  max_bytes = 2**31 - 1\n",
    "  data = bytearray(n_bytes)\n",
    "\n",
    "  bytes_out = pickle.dumps(save)\n",
    "  with open(pickle_file, 'wb') as f_out:\n",
    "      for idx in range(0, len(bytes_out), max_bytes):\n",
    "          f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "          \n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
