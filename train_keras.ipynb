{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools, random, imageio, sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faces_folder = \"faces\"\n",
    "pickle_file = \"faces.pickle\"\n",
    "trained_models_folder = \"./tf_trained/\"\n",
    "\n",
    "pixel_depth = 255.0\n",
    "image_size = 128\n",
    "num_labels = 2\n",
    "input_size = image_size * image_size * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  compare_elements = np.argmax(predictions, 1) == np.argmax(labels, 1)\n",
    "  return (100.0 * np.sum(compare_elements) / predictions.shape[0])\n",
    "\n",
    "def makedir(path):\n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "def accuracy_averaged(steps, accuracy_over_time, every_index=10):\n",
    "  new_accuracy = np.mean(np.array(accuracy_over_time).reshape(-1, every_index), axis=1)\n",
    "  new_steps = steps[0::every_index]\n",
    "  return new_steps, new_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (23014, 32768) (23014, 2)\n",
      "Validation set (1275, 32768) (1275, 2)\n",
      "Test set (1275, 32768) (1275, 2)\n"
     ]
    }
   ],
   "source": [
    "n_bytes = 2**31\n",
    "max_bytes = 2**31 - 1\n",
    "bytes_in = bytearray(0)\n",
    "\n",
    "pickle_file_size = os.path.getsize(pickle_file)\n",
    "with open(pickle_file, 'rb') as f_in:\n",
    "  for _ in range(0, pickle_file_size, max_bytes):\n",
    "    bytes_in += f_in.read(max_bytes)\n",
    "save = pickle.loads(bytes_in)\n",
    "\n",
    "train_dataset = save['train_dataset']\n",
    "train_labels = save['train_labels']\n",
    "valid_dataset = save['valid_dataset']\n",
    "valid_labels = save['valid_labels']\n",
    "test_dataset = save['test_dataset']\n",
    "test_labels = save['test_labels']\n",
    "del save  # hint to help gc free up memory\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done shuffle\n"
     ]
    }
   ],
   "source": [
    "# shuffleing the data\n",
    "train_dataset, train_labels = sklearn.utils.shuffle(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = sklearn.utils.shuffle(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = sklearn.utils.shuffle(test_dataset, test_labels)\n",
    "print(\"done shuffle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23014/23014 [==============================] - 331s 14ms/step - loss: 0.7042 - acc: 0.5089\n",
      "Epoch 2/100\n",
      "23014/23014 [==============================] - 262s 11ms/step - loss: 0.6917 - acc: 0.5172\n",
      "Epoch 3/100\n",
      "23014/23014 [==============================] - 241s 10ms/step - loss: 0.6906 - acc: 0.5194\n",
      "Epoch 4/100\n",
      "23014/23014 [==============================] - 282s 12ms/step - loss: 0.6884 - acc: 0.5298\n",
      "Epoch 5/100\n",
      "23014/23014 [==============================] - 244s 11ms/step - loss: 0.6881 - acc: 0.5302\n",
      "Epoch 6/100\n",
      "23014/23014 [==============================] - 226s 10ms/step - loss: 0.6866 - acc: 0.5371\n",
      "Epoch 7/100\n",
      "23014/23014 [==============================] - 242s 11ms/step - loss: 0.6839 - acc: 0.5408\n",
      "Epoch 8/100\n",
      "23014/23014 [==============================] - 202s 9ms/step - loss: 0.6835 - acc: 0.5471\n",
      "Epoch 9/100\n",
      "23014/23014 [==============================] - 192s 8ms/step - loss: 0.6814 - acc: 0.5466\n",
      "Epoch 10/100\n",
      "23014/23014 [==============================] - 204s 9ms/step - loss: 0.6768 - acc: 0.5555\n",
      "Epoch 11/100\n",
      "23014/23014 [==============================] - 223s 10ms/step - loss: 0.6723 - acc: 0.5609\n",
      "Epoch 12/100\n",
      "23014/23014 [==============================] - 192s 8ms/step - loss: 0.6658 - acc: 0.5717\n",
      "Epoch 13/100\n",
      "23014/23014 [==============================] - 190s 8ms/step - loss: 0.6608 - acc: 0.5772\n",
      "Epoch 14/100\n",
      "23014/23014 [==============================] - 210s 9ms/step - loss: 0.6538 - acc: 0.5872\n",
      "Epoch 15/100\n",
      "23014/23014 [==============================] - 207s 9ms/step - loss: 0.6434 - acc: 0.6020\n",
      "Epoch 16/100\n",
      "23014/23014 [==============================] - 194s 8ms/step - loss: 0.6340 - acc: 0.6102\n",
      "Epoch 17/100\n",
      "23014/23014 [==============================] - 221s 10ms/step - loss: 0.6238 - acc: 0.6233\n",
      "Epoch 18/100\n",
      "23014/23014 [==============================] - 196s 8ms/step - loss: 0.6129 - acc: 0.6341\n",
      "Epoch 19/100\n",
      "23014/23014 [==============================] - 192s 8ms/step - loss: 0.6044 - acc: 0.6418\n",
      "Epoch 20/100\n",
      "23014/23014 [==============================] - 225s 10ms/step - loss: 0.5922 - acc: 0.6539\n",
      "Epoch 21/100\n",
      "23014/23014 [==============================] - 196s 9ms/step - loss: 0.5838 - acc: 0.6652\n",
      "Epoch 22/100\n",
      "23014/23014 [==============================] - 195s 8ms/step - loss: 0.5703 - acc: 0.6819\n",
      "Epoch 23/100\n",
      "23014/23014 [==============================] - 214s 9ms/step - loss: 0.5610 - acc: 0.6872\n",
      "Epoch 24/100\n",
      "23014/23014 [==============================] - 229s 10ms/step - loss: 0.5414 - acc: 0.7036\n",
      "Epoch 25/100\n",
      "23014/23014 [==============================] - 216s 9ms/step - loss: 0.5330 - acc: 0.7153\n",
      "Epoch 26/100\n",
      "23014/23014 [==============================] - 216s 9ms/step - loss: 0.5222 - acc: 0.7258\n",
      "Epoch 27/100\n",
      "23014/23014 [==============================] - 188s 8ms/step - loss: 0.5090 - acc: 0.7392\n",
      "Epoch 28/100\n",
      "23014/23014 [==============================] - 212s 9ms/step - loss: 0.5030 - acc: 0.7442\n",
      "Epoch 29/100\n",
      "23014/23014 [==============================] - 196s 9ms/step - loss: 0.4830 - acc: 0.7595\n",
      "Epoch 30/100\n",
      "23014/23014 [==============================] - 182s 8ms/step - loss: 0.4772 - acc: 0.7664\n",
      "Epoch 31/100\n",
      "23014/23014 [==============================] - 188s 8ms/step - loss: 0.4613 - acc: 0.7826\n",
      "Epoch 32/100\n",
      "23014/23014 [==============================] - 231s 10ms/step - loss: 0.4581 - acc: 0.7833\n",
      "Epoch 33/100\n",
      "23014/23014 [==============================] - 190s 8ms/step - loss: 0.4465 - acc: 0.7942\n",
      "Epoch 34/100\n",
      "23014/23014 [==============================] - 214s 9ms/step - loss: 0.4360 - acc: 0.7992\n",
      "Epoch 35/100\n",
      "23014/23014 [==============================] - 209s 9ms/step - loss: 0.4315 - acc: 0.8069\n",
      "Epoch 36/100\n",
      "23014/23014 [==============================] - 212s 9ms/step - loss: 0.4261 - acc: 0.8086\n",
      "Epoch 37/100\n",
      "23014/23014 [==============================] - 227s 10ms/step - loss: 0.4149 - acc: 0.8131\n",
      "Epoch 38/100\n",
      "23014/23014 [==============================] - 209s 9ms/step - loss: 0.4108 - acc: 0.8185\n",
      "Epoch 39/100\n",
      "23014/23014 [==============================] - 189s 8ms/step - loss: 0.4008 - acc: 0.8257\n",
      "Epoch 40/100\n",
      "23014/23014 [==============================] - 214s 9ms/step - loss: 0.3971 - acc: 0.8264\n",
      "Epoch 41/100\n",
      "23014/23014 [==============================] - 227s 10ms/step - loss: 0.3914 - acc: 0.8293\n",
      "Epoch 42/100\n",
      "23014/23014 [==============================] - 234s 10ms/step - loss: 0.3916 - acc: 0.8312\n",
      "Epoch 43/100\n",
      "23014/23014 [==============================] - 250s 11ms/step - loss: 0.3808 - acc: 0.8370\n",
      "Epoch 44/100\n",
      "23014/23014 [==============================] - 350s 15ms/step - loss: 0.3802 - acc: 0.8395\n",
      "Epoch 45/100\n",
      "23014/23014 [==============================] - 361s 16ms/step - loss: 0.3681 - acc: 0.8456\n",
      "Epoch 46/100\n",
      "23014/23014 [==============================] - 367s 16ms/step - loss: 0.3658 - acc: 0.8470\n",
      "Epoch 47/100\n",
      "23014/23014 [==============================] - 306s 13ms/step - loss: 0.3623 - acc: 0.8497\n",
      "Epoch 48/100\n",
      "23014/23014 [==============================] - 239s 10ms/step - loss: 0.3590 - acc: 0.8486\n",
      "Epoch 49/100\n",
      "23014/23014 [==============================] - 224s 10ms/step - loss: 0.3667 - acc: 0.8464\n",
      "Epoch 50/100\n",
      "23014/23014 [==============================] - 219s 9ms/step - loss: 0.3510 - acc: 0.8557\n",
      "Epoch 51/100\n",
      "23014/23014 [==============================] - 222s 10ms/step - loss: 0.3491 - acc: 0.8574\n",
      "Epoch 52/100\n",
      "23014/23014 [==============================] - 217s 9ms/step - loss: 0.3432 - acc: 0.8612\n",
      "Epoch 53/100\n",
      "23014/23014 [==============================] - 221s 10ms/step - loss: 0.3403 - acc: 0.8603\n",
      "Epoch 54/100\n",
      "23014/23014 [==============================] - 217s 9ms/step - loss: 0.3410 - acc: 0.8616\n",
      "Epoch 55/100\n",
      "23014/23014 [==============================] - 215s 9ms/step - loss: 0.3355 - acc: 0.8648\n",
      "Epoch 56/100\n",
      "23014/23014 [==============================] - 224s 10ms/step - loss: 0.3362 - acc: 0.8648\n",
      "Epoch 57/100\n",
      "23014/23014 [==============================] - 219s 10ms/step - loss: 0.3368 - acc: 0.8633\n",
      "Epoch 58/100\n",
      "23014/23014 [==============================] - 216s 9ms/step - loss: 0.3354 - acc: 0.8647\n",
      "Epoch 59/100\n",
      "23014/23014 [==============================] - 241s 10ms/step - loss: 0.3354 - acc: 0.8646\n",
      "Epoch 60/100\n",
      "23014/23014 [==============================] - 285s 12ms/step - loss: 0.3294 - acc: 0.8686\n",
      "Epoch 61/100\n",
      "23014/23014 [==============================] - 283s 12ms/step - loss: 0.3201 - acc: 0.8736\n",
      "Epoch 62/100\n",
      "23014/23014 [==============================] - 259s 11ms/step - loss: 0.3227 - acc: 0.8717\n",
      "Epoch 63/100\n",
      "23014/23014 [==============================] - 236s 10ms/step - loss: 0.3244 - acc: 0.8709\n",
      "Epoch 64/100\n",
      "23014/23014 [==============================] - 234s 10ms/step - loss: 0.3179 - acc: 0.8734\n",
      "Epoch 65/100\n",
      "23014/23014 [==============================] - 240s 10ms/step - loss: 0.3297 - acc: 0.8684\n",
      "Epoch 66/100\n",
      "23014/23014 [==============================] - 244s 11ms/step - loss: 0.3224 - acc: 0.8733\n",
      "Epoch 67/100\n",
      "23014/23014 [==============================] - 237s 10ms/step - loss: 0.3184 - acc: 0.8743\n",
      "Epoch 68/100\n",
      "23014/23014 [==============================] - 253s 11ms/step - loss: 0.3152 - acc: 0.8751\n",
      "Epoch 69/100\n",
      "23014/23014 [==============================] - 249s 11ms/step - loss: 0.3181 - acc: 0.8747\n",
      "Epoch 70/100\n",
      "23014/23014 [==============================] - 238s 10ms/step - loss: 0.3203 - acc: 0.8741\n",
      "Epoch 71/100\n",
      "23014/23014 [==============================] - 237s 10ms/step - loss: 0.3166 - acc: 0.8758\n",
      "Epoch 72/100\n",
      "23014/23014 [==============================] - 231s 10ms/step - loss: 0.3186 - acc: 0.8742\n",
      "Epoch 73/100\n",
      "23014/23014 [==============================] - 287s 12ms/step - loss: 0.3160 - acc: 0.8759\n",
      "Epoch 74/100\n",
      "23014/23014 [==============================] - 284s 12ms/step - loss: 0.3105 - acc: 0.8782\n",
      "Epoch 75/100\n",
      "23014/23014 [==============================] - 279s 12ms/step - loss: 0.3091 - acc: 0.8786\n",
      "Epoch 76/100\n",
      "23014/23014 [==============================] - 273s 12ms/step - loss: 0.3109 - acc: 0.8793\n",
      "Epoch 77/100\n",
      "23014/23014 [==============================] - 236s 10ms/step - loss: 0.3106 - acc: 0.8784\n",
      "Epoch 78/100\n",
      "23014/23014 [==============================] - 247s 11ms/step - loss: 0.3126 - acc: 0.8774\n",
      "Epoch 79/100\n",
      "23014/23014 [==============================] - 244s 11ms/step - loss: 0.3069 - acc: 0.8807\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23014/23014 [==============================] - 232s 10ms/step - loss: 0.3043 - acc: 0.8812\n",
      "Epoch 81/100\n",
      "23014/23014 [==============================] - 191s 8ms/step - loss: 0.3069 - acc: 0.8807\n",
      "Epoch 82/100\n",
      "23014/23014 [==============================] - 179s 8ms/step - loss: 0.3051 - acc: 0.8812\n",
      "Epoch 83/100\n",
      "23014/23014 [==============================] - 180s 8ms/step - loss: 0.3030 - acc: 0.8821\n",
      "Epoch 84/100\n",
      "23014/23014 [==============================] - 179s 8ms/step - loss: 0.3047 - acc: 0.8826\n",
      "Epoch 85/100\n",
      "23014/23014 [==============================] - 181s 8ms/step - loss: 0.3128 - acc: 0.8762\n",
      "Epoch 86/100\n",
      "23014/23014 [==============================] - 182s 8ms/step - loss: 0.3026 - acc: 0.8826\n",
      "Epoch 87/100\n",
      "23014/23014 [==============================] - 181s 8ms/step - loss: 0.3079 - acc: 0.8802\n",
      "Epoch 88/100\n",
      "23014/23014 [==============================] - 180s 8ms/step - loss: 0.3077 - acc: 0.8805\n",
      "Epoch 89/100\n",
      "23014/23014 [==============================] - 180s 8ms/step - loss: 0.3021 - acc: 0.8829\n",
      "Epoch 90/100\n",
      "23014/23014 [==============================] - 190s 8ms/step - loss: 0.3022 - acc: 0.8812\n",
      "Epoch 91/100\n",
      "23014/23014 [==============================] - 183s 8ms/step - loss: 0.3032 - acc: 0.8817\n",
      "Epoch 92/100\n",
      "23014/23014 [==============================] - 180s 8ms/step - loss: 0.2995 - acc: 0.8848\n",
      "Epoch 93/100\n",
      "23014/23014 [==============================] - 181s 8ms/step - loss: 0.3006 - acc: 0.8837\n",
      "Epoch 94/100\n",
      "23014/23014 [==============================] - 193s 8ms/step - loss: 0.3030 - acc: 0.8825\n",
      "Epoch 95/100\n",
      "23014/23014 [==============================] - 183s 8ms/step - loss: 0.2999 - acc: 0.8835\n",
      "Epoch 96/100\n",
      "23014/23014 [==============================] - 180s 8ms/step - loss: 0.3000 - acc: 0.8832\n",
      "Epoch 97/100\n",
      "23014/23014 [==============================] - 181s 8ms/step - loss: 0.2968 - acc: 0.8842\n",
      "Epoch 98/100\n",
      "23014/23014 [==============================] - 181s 8ms/step - loss: 0.2937 - acc: 0.8863\n",
      "Epoch 99/100\n",
      "23014/23014 [==============================] - 182s 8ms/step - loss: 0.2969 - acc: 0.8849\n",
      "Epoch 100/100\n",
      "23014/23014 [==============================] - 182s 8ms/step - loss: 0.2972 - acc: 0.8849\n",
      "1275/1275 [==============================] - 5s 4ms/step\n",
      "Score [0.28121841182895735, 0.8956862757252712]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "layer_sizes = {\n",
    "  \"1\": 2048,\n",
    "  \"2\": 1024,\n",
    "  \"3\": 64\n",
    "}\n",
    "\n",
    "dropouts = {\n",
    "  \"1\": 0.5,\n",
    "  \"2\": 0.5,\n",
    "  \"3\": 0.5,\n",
    "}\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(layer_sizes[\"1\"], activation=tf.nn.relu, input_shape=(32768,), name=\"input\"))\n",
    "model.add(tf.keras.layers.Dropout(dropouts[\"1\"],  name=\"dropout_input\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(layer_sizes[\"2\"], activation=tf.nn.relu, name=\"layer_1\"))\n",
    "model.add(tf.keras.layers.Dropout(dropouts[\"2\"], name=\"dropout_layer_1\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(layer_sizes[\"3\"], activation=tf.nn.relu, name=\"layer_2\"))\n",
    "model.add(tf.keras.layers.Dropout(dropouts[\"3\"], name=\"dropout_layer_2\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(num_labels, activation=tf.nn.softmax, name=\"output\"))\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset, train_labels,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size)\n",
    "\n",
    "score = model.evaluate(test_dataset, test_labels, batch_size=batch_size)\n",
    "print(\"Score\", score)\n",
    "\n",
    "model.save(\"same_people_detector_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
