{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, itertools, random, imageio, sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faces_folder = \"faces\"\n",
    "pickle_file = \"faces.pickle\"\n",
    "trained_models_folder = \"./tf_trained/\"\n",
    "\n",
    "pixel_depth = 255.0\n",
    "image_size = 128\n",
    "num_labels = 2\n",
    "input_size = image_size * image_size * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (23014, 32768) (23014, 2)\n",
      "Validation set (1275, 32768) (1275, 2)\n",
      "Test set (1275, 32768) (1275, 2)\n"
     ]
    }
   ],
   "source": [
    "n_bytes = 2**31\n",
    "max_bytes = 2**31 - 1\n",
    "bytes_in = bytearray(0)\n",
    "\n",
    "pickle_file_size = os.path.getsize(pickle_file)\n",
    "with open(pickle_file, 'rb') as f_in:\n",
    "  for _ in range(0, pickle_file_size, max_bytes):\n",
    "    bytes_in += f_in.read(max_bytes)\n",
    "save = pickle.loads(bytes_in)\n",
    "\n",
    "train_dataset = save['train_dataset']\n",
    "train_labels = save['train_labels']\n",
    "valid_dataset = save['valid_dataset']\n",
    "valid_labels = save['valid_labels']\n",
    "test_dataset = save['test_dataset']\n",
    "test_labels = save['test_labels']\n",
    "del save  # hint to help gc free up memory\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done shuffle\n"
     ]
    }
   ],
   "source": [
    "# shuffleing the data\n",
    "train_dataset, train_labels = sklearn.utils.shuffle(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = sklearn.utils.shuffle(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = sklearn.utils.shuffle(test_dataset, test_labels)\n",
    "print(\"done shuffle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  compare_elements = np.argmax(predictions, 1) == np.argmax(labels, 1)\n",
    "  return (100.0 * np.sum(compare_elements) / predictions.shape[0])\n",
    "\n",
    "def makedir(path):\n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "def accuracy_averaged(steps, accuracy_over_time, every_index=10):\n",
    "  new_accuracy = np.mean(np.array(accuracy_over_time).reshape(-1, every_index), axis=1)\n",
    "  new_steps = steps[0::every_index]\n",
    "  return new_steps, new_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 hidden layer L2 optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 0.4\n",
    "l2_reg_beta = 0.001\n",
    "num_steps = 20001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  # input data\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size * 2))\n",
    "  tf_train_labels  = tf.placeholder(tf.float32, shape=(batch_size, 2))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset  = tf.constant(test_dataset)\n",
    "  \n",
    "  # hidden nodes\n",
    "  hidden_nodes = 1024\n",
    "  hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size * 2, hidden_nodes]))\n",
    "  hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "  hidden_comp = tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases\n",
    "  hidden_layer = tf.nn.relu(hidden_comp)\n",
    "  \n",
    "  # variables\n",
    "  weights = tf.Variable(tf.truncated_normal([hidden_nodes, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # training\n",
    "  logits = tf.matmul(hidden_layer, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits))\n",
    "  loss += (l2_reg_beta * tf.nn.l2_loss(hidden_weights) + l2_reg_beta * tf.nn.l2_loss(weights))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "  # valid prediction\n",
    "  valid_relu = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(valid_relu, weights) + biases)\n",
    "  \n",
    "  # test prediction\n",
    "  test_relu = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "  test_prediction  = tf.nn.softmax(tf.matmul(test_relu, weights) + biases)\n",
    "  \n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\\n\")\n",
    "  \n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    \n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    \n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 100 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\\n\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "      \n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3 hidden layer and with L2 optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "\n",
      "Minibatch loss at step 0: 3.463964\n",
      "Minibatch accuracy: 51.6%\n",
      "Validation accuracy: 47.1%\n",
      "\n",
      "Minibatch loss at step 250: 3.162962\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 58.0%\n",
      "\n",
      "Minibatch loss at step 500: 2.870050\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 74.3%\n",
      "\n",
      "Minibatch loss at step 750: 2.629769\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 77.7%\n",
      "\n",
      "Minibatch loss at step 1000: 2.370912\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.1%\n",
      "\n",
      "Minibatch loss at step 1250: 2.127718\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.3%\n",
      "\n",
      "Minibatch loss at step 1500: 1.991231\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.6%\n",
      "\n",
      "Minibatch loss at step 1750: 1.804081\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.6%\n",
      "\n",
      "Minibatch loss at step 2000: 1.700452\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 76.1%\n",
      "\n",
      "Minibatch loss at step 2250: 1.536572\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.7%\n",
      "\n",
      "Minibatch loss at step 2500: 1.403520\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 84.4%\n",
      "\n",
      "Minibatch loss at step 2750: 1.262288\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 82.1%\n",
      "\n",
      "Minibatch loss at step 3000: 1.267410\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.3%\n",
      "\n",
      "Minibatch loss at step 3250: 1.172164\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.9%\n",
      "\n",
      "Minibatch loss at step 3500: 1.092289\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 83.5%\n",
      "\n",
      "Minibatch loss at step 3750: 1.061162\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.9%\n",
      "\n",
      "Minibatch loss at step 4000: 0.884450\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 86.5%\n",
      "\n",
      "Minibatch loss at step 4250: 0.877940\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.1%\n",
      "\n",
      "Minibatch loss at step 4500: 0.856154\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.9%\n",
      "\n",
      "Minibatch loss at step 4750: 0.888666\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.4%\n",
      "\n",
      "  Test accuracy: 85.1%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XecFPX9+PHXm7ujdzg6clRRkXoi\nKCDFCvbYTUKMBjX2mOhpjH6jXyOWaPQXvxqjiSY27BhQFBFbVJBeRIpwCCfl6P2Au8/vj5292zK7\nO3s7s/X9fDzucbszszOf2TLv+XQxxqCUUip31Ul1ApRSSqWWBgKllMpxGgiUUirHaSBQSqkcp4FA\nKaVynAYCpZTKcRoIlFIqx2kgUEqpHKeBQCmlclx+qhPgROvWrU1RUVGqk6GUUhll7ty5W4wxhbG2\ny4hAUFRUxJw5c1KdDKWUyigistbJdlo0pJRSOU4DgVJK5TgNBEopleM0ECilVI7TQKCUUjlOA4FS\nSuU4DQRKKZXjNBAoFcH+g5W8NW89xhgqqwyvfbOOw5VVqU5WRlm8ficL1+1IdTIcOXCokjfm+j7v\nXJMRHcqUSoV7p3zLK7N/oH2zBqwq38Mf3lnC7orDXDmsa6qTljHO+usXAJROHJfilMT28AfLee6L\nNbRsVMDo3m1TnZyk0hyBUhFs3nUAgL0Vh9mx9yAA263/Kvts3l0BwO4Dh1OckuTTQKCUDWMMM77b\nHL4c58UG//zvGqYu2uBmsmx9uHQjz3z2vefHUdlLi4aUsrH/UGXQc5H49/HH/3wLwLi+3haLTPj3\nXN//Ed09PY7KXpojUMqGUHPlD8wD5GA9osoBGghUWpj4/ncUlUwF4KVZaykqmcqBkLvy7zbuoqhk\nKovW+1qhFJVM5YH3l8V1nP0HKykqmcqrs3+Iul1oDkCsBYFx4IH3l9H1jqlxHT9Rm3YdoKhkKjOW\nbQpb1+2Oqfzpvejvx21vLGTQfdMB+HRFOUUlU/lxx/6w7QbdN53b31gUtGzkwzO59sW5/PurUopK\nplJxOPjzWbbB9/k8/tFKikqmVtex+G220v7Rt+FpT9SSsp0UlUzl2x93AfDG3PUUlUxl+96DFJVM\n5aFpvu/XzOWbuf7leZw48WMAJn3zA0UlU9l30Fm9QFWVoahkasJFccMf+pjrX55XnTa/W19bSFHJ\nVIpKptLz9+8ldIx4aCBQaeHpT2t+WI9/tBKAHfsOBW3zsVVm/97ijdXL/vbp6riOs2WPr0LwyU9W\n1SqdgTmCv326Ouk5hMXrdwLw0qzwQFZl4JnPor8fr81Zz1arwvsVax8LbJp3bt17kElz1gUtK926\nj/eXbOTxGb7PZ+f+4M9nunWBf+yjFQAstS7K1Wkv86fd0cjIcflw6cagNDxlfb7fbdwNwP994vt+\nvTLrB6Ys2kCZFfz+OtO3XblVURzLoSpf8+FHPliRUHrXbdvPFKv+yJ82gDfnra85VmXyvlwaCHLQ\n9r0H06r1y5ote22Xl+3YR8Xhyur1/uIau7Sv374v6A714OEq1m3bR2WVYe1W+/2H2rz7ANv2HuSb\n0m2s2rwnaJ0/h7BlTwWlW/ayMyBI7T9YyYadvgvLxp0HHN9d+q3bto8NO/ez+8AhftyxnwOHKsPO\nZ9veg+zYF37eKzftDltWumUvVVWGJWU72bzrADv2HWSbzXvmP6fy3RXsqbBPc6TPxk5oNcrhqpoL\n2arNu6sD0Nqt+zhwqDIoJxL4vvnT7z++o3b91Tk2Yz31PbfL7QTy7/rAoej9Q0I/14OVVUHfAaci\nnc/Bw1Ws374vbHlosPWKVhbnoAFW0UA6tO1+f/EGrn1pnu26nzz1VfXjKTcMq348ac46Hrygb/Xz\nisOVDHtwJuP6tufJywYCUPLWIt6aV8YvTiji+S9L+fy2UXRu2TBqWgbfPyNmet+Yu5435q4nr07N\nZe+nz81i7trtlE4cx5AHZtCnY1Om3DA85r7AF3yGPzQTgMIm9SjfXcFxRS34pnQ7Z/XrwP+7dAAA\nA63P7NmfF1e/dk/FYU557LOwfY585BPOH9CRt+aXBS2P9Hnf8+5S/vbp93x5x5iwdaMe+cTx9yS0\nOC2w2O7kR2vSuXrLXnr/YVpQmoY8MIO+nZrx6EX9OfnRT7nl5F4UF7Xg8mdn8fAFfbmwuLOjNIRe\nY299faGj7S9/dhZDu7eKuJ0/fa9fM7R6Wb97P4zrN/TFyi389LlZ/PnCfmHrSt5cFPZ5AZzwwAyW\n3nu642PUluYIVEp9u2FX7I3w3fFHarnjz0J/EtDc85Pl5QDMXO5btnn3gfAXxkFC7ncrA+52567d\nHrRuSZmzc4Lg4i9/8cQ3pb79fWLTfDXwPdh/sDJsvZ/dRSWaH3fG8/7YfxAS8gGtLneemwBYtH5n\ndc5qdunW6tzOEqtIKRp/XPZ/KvE28vIXGcZKXyJFgSus81lscz6frCi3fc3eKJ+xmzRHoGxt3VPB\n5yu3sO9gJRcM6kTdfN89Q2WVYdI367iwuBMFeZHvI/zbXVTcifwo24X+YKd/u6m6Y0+gfQcrg7bd\ntCv8wrX3YCWzVm/l+G6tOGQNBbF2qy+7bQyU7dhfXYYcms4LiztFTOPH323miBi5CYClP0a+YH26\nopzOLRqwuGwnI3oW0qJRXYDqyk2n/NuX767g3YU/xvXaQHsqDtsG4ckLyhjRM3iK27lrt9l+1j9s\n3ceSsp2M7t2W6d9u4uEPltcqLYFFfXuszlzGBFzUrQDz7Y+7WLNlL3sqDrFu234GdWlB55YNuOSZ\nr9my56D1OudX6qc++b66rgDgP9b7uS/g4vv16q1URdnnpl0HmLVmG7sPHKJ7YWMa18unT8dmHKqs\n4rU567jkuCPIqyMcOFTJpG/WRdxPtKCeDBoIlK1rX5zH7NJtgO9u6cYxPQF4c+567nx7Mdv3HeS6\nUT0ivv7l2T/wh3eWsLfiML8a0S3idqE/sV/9y35u6vunLuPqk2r2c/yf7ItxLn7ma0onjrPtHXrm\nE5+z3boD9/+2J32zjjvfXhy1LPaV2T9QckbviOv9xj3xRcR14/8xu/rxkG4teXWCr4jh5kkLIr7G\n7vLz5+m+SsrFZTtt7yydunvykuog6bd++z5uenUBQ7sFF5EEFtEFuuBp3/LSieMifm5OXP9KTdGg\nv5jwy++3cvJRwcM8jH3i81ofw86DAa11Av3Pu0u5dPARAFzyzNdB60JjwmV//5rvQ3I+pRPH8ffP\nV/PQtOXUEeHSwUfw2PQVLLepz/EL7beSbFo0pGwF3ikFVjTu2O9sqIVd1oV1u00FZ21s3XswrHgm\nHgaqg0AgfwDwn1cktT9yuHXboldgJoP/DjrQwcO+XNRGm9xWoNp0rotmQ1zFUtH5L9SJpLHicOSK\n49Ce5eu323+W/iI//+9gaxo1zrCjOYIM8/b89WzcWcG1I93pRTpl0Y+sKd/LDdYdv52Kw1Vc99I8\n+nduXt20E+CvH6+kS6tGnNWvQ8TX/v3z1cxdu53CJvV49KL+9LrrfQAuGNSJVo3q8rcYzR0D3R+h\njXyfez4Ieu7vjxDowqeD72oPHKri2hfn0qZJPSB2M9RXo2Tr7RwMuJg8+mFwkUnZDl8LoaoYA5nu\nqThMUclUVt5/RlzHjuT6l2vuvD+zKZMe/edPgfhaCoH9++3U5AVlEesS/PUwz39ZSpP6zi5Vb88v\nY9rSjWGtvvw+dNiHYdB906m0KRL647vfBj2PFjT83lu8gTfm1jQLff7LUkdpSCYNBBnmlkm+VhBu\nBYLrX54PEDUQfL6ynPXb9zN1cfC4OY986CumiBYIDlUaZq3xFTH9bEiX6uWBP4xU2LKngveXbIy9\noSXei+P8H2oqkJ/4OLzPwutz1jtuZurWMM5TkjDuUbxuejVy0Zi/DwDA/7N5D+2UxWgu6lSkO/jQ\nvhVO/DpCq7h0okVDSnnA7m4yUDyNT0Jb4yjlNs0RKMBXbPD5yi0svOfUsHWxGmJc/e85zPthB9/8\n/mQArnt5nu2omxeHVLxls8v+Pivq+vumfBt1faCfPPVloslxldNeuIk6HKvsLI35e3g/8L59hXS6\n0UCggMSKDT5YGlzumoyhl1X221uR2pY0ucTToiERuUlElojIUhG52VrWUkSmi8hK638LL9OQq0q3\n7A2qsHTKX8kWWNZqd2e2yKbp4qcryuMuS1dKpZ5ngUBE+gC/AgYD/YAzRaQHUALMMMb0BGZYz5WL\ndu4/xMhHPuHOtxfH/dqTH/00bGTLTbvCiwJmWxXAgcb/YzajHvkk7mMqZSdT5w7+vty+xVJtJaOz\nmZc5gqOAWcaYfcaYw8CnwPnAOcAL1jYvAOd6mIactNcaQOy/q7bU6vWho0YqlQrRevSms00u9ouA\nmhFPveRlIFgCDBeRViLSEBgLdAbaGmP8hcgbgdyaJTpOVVWGf39VGjb2u58xhhe/Xht017DMGjpg\nw84D/LA1fERDv0jrHp2e2BC7Srlh5nL78XfSndu9hJPRZsyzQGCMWQY8CHwITAMWAJUh2xgitKQT\nkQkiMkdE5pSXZ+YXwg3vLCjjD5OX8tcI7ahnLNvMXe8sCRrp8coXarr7n/aX8NEp/U79y6fuJVQp\nBdT0r3FLnSQ0H/a0stgY85wxZpAxZgSwHVgBbBKR9gDW//AhFn2vfcYYU2yMKS4sLLTbJCf4x4mP\nNFTDXqtTkt148xD97iTWGOxKqfhtdTCSaTyS0Y3E0+ajItLGGLNZRI7AVz8wBOgKjAcmWv8ne5mG\nTFZxuJK7Jy+Nuo2/s9GURRs4XDmXaUvDe8seOFRJ/YI8Ji8oY/nGyANfKaUSl4l1G173I3hTRFoB\nh4DrjDE7RGQi8JqIXAmsBS7yOA0Za8EP8Q0tYBcEAL78fguje7eN2p1fKeUOt+NAMuKKp4HAGBM2\nTZMxZisQPhWSClOnjjt5wkRG7VRKZT8dayiJpi7aQFHJVDbaNC978eu1FJVMZdeBmqGSAyuJJs//\nMWiUx6KSqXy9equj417x/DcJjRCplHLO7Rv4ZBQ0aSBIole/+QHAdoKKf/x3DQCbA8aCD8wQ7LaZ\nXHxaHKNnKqWSIxM7wmkgSIHoX5Saq3+eS0VDSqnksZsAKRF7bW4C3aaBII05aT+soUKp7ObmDG6R\naCBIFzaZhFhxQIepV0q5QQNBEkWbYMRUb1OzLBk9CpVSSgNBCjitStI6AqVURo81pMLF+4HGigOC\naPGQUiphOkNZmgm8ri8piz4c9D/+u4Z//Nfb9Cilsp/mCFLBpmzIrknpzZN0SAillPc0EKSJmspi\nLetRSiWXFg256JfPf8OnK8r5/k9ja72PcU98zr4kTE2nlFJ+miNw0cffbaayKnKbICc3+xoEVCoN\nOKJ5qpMQ5nenHZnqJHiqW2GjqOuTUUiggSCJyrbvD3q+bts+dlgTzmTg8CQqC11zUvdUJyFMq0Z1\nU50ET53YvXWqk6CBIJlWbt4DgLFqBIY/NJMxf9bpIpWKxouOlUWtGrq+z9oySRlfNDoNBCm2NcIU\nk8pdX90xOtVJ8NQXt4/iy5LRLLv39KDl/TrHV9RT25zp3LtOjrjuiJbJvei+f1PYNCjV/n3lYGbd\nOYaPbx2ZvAQF+PqO+KdiScZ8IhoIkuDg4Sr+9un31c+f/3JtWHPRdLgryGbtmzVIdRI81alFQzo0\nb0CDunlBy+vmJacVWqvG9SKua96wIClp8OvUwvdZNwp5LwCaNSigbdP6rk36FK92zeqHLUuHYmEN\nBEnwr69KeeD976qff7ainEXrd6YuQSpI307NPN3/Cd1bubq/8wd0dLztZccfEefe7a9KZ/frEPEV\n951zTNQ9/vZUbyp7Bx7RnEFdWkTd5mdDunhy7GyjgSAJ9tiMJ36wsiroeTrcFWSKNk0i3336nXJ0\nW8f7e/f6YWHLxg+tuYD88sSutq976vKBQc/t7kAB7j7raMdpAbhymP3x/EYf1cbRfgryhJ5tmsR1\n7EjGn1Bku7x04jh+NtR+HUDd/DqM6FWY2MEj3Ly/9esTefPaEyidOI7SieNst7nv3D6ODhFPcM1G\nGgg88ubc9fz29YUAzF27PWz9r1+aV/14wL0fsj6kRZGKrH6B/QXXTQV5NT+NSMV2ocULdp0BRdwv\n443SQjlMvBWteXXsLwm1ra9tGCE4xqMgzuIt/zmHFpMFrkul/JDvTayPU5uPZrBbX1/IG3PXA/D5\nyi1h68t3V1Q/dntGo0x19UndaB2lrNnv/vPs7/IC7+Lj/e1MuaEmV3DlsK7cfEqvqNvfNe6osAtU\nsqYorHIYCQThqPZNuGlMz7B1kd7D0b3bcO3I7sy+M7hSc0Dn5gzvGb2Z45/OOzbo+clHteGNa04I\nWnbn2N7cE2cO6dz+NXfrJ/aIXczWqF4+JWf05rWrh4atO6ZD07iO7Zbfjz2Ke60itKk3hldmP3/F\ncUw8/9iw5cmigUCljTvOOIqmDWJ3dm8ZoV35H8+pubjFexfVp2NNPcEfzjyaxvVq0mF3fb9qeLe4\nhwPp2aaxo+1ixZNonRaDiC+XcotNUOtRWJOW3u1qio/y6gi3n96bNk3rBxXBiQjdWkfv+BRaH/Hs\n+OPoEXLOE0Z054oIRW0RT0OkOmfxq+HdAGLWDVxzUne6FYa/3xE/M4/vuo/t1IyfW0VoR7YLLq4z\nBkYe2YZLBh9Bk/qpGexBA4HKSslochd6BLuLTN+OzWhs/bh7tbMvr+8S0qbd3+olkrZNw1ue2OkT\ncPfbO+TYzZLckidR/kCdqXN0RCuSCmxem6q6Qg0EKinq5qXuq/aelRV/57oTg5a/ee1Q3r3+RLuX\nRHVrjGIjgMcu7sfTPx3Iv355PB2bN+CVXw3h4Qv62m771rXBxSe/iFAxC3BWvw4MCymi+ex3o2y3\n/ecVg6sfvzphSPXjl646nt7taoJEvlXEFVq0k0wXF3dmUkAaQz07vpjXrxlKA6t+yO1iOEH4/Db7\n99HOVcO68p/rhzkuzokUB/7xi2ImjOjm+Lhe0UCgkuKogLvTtk1j1wMkKvCHd7R17P4hnasGdWlJ\n307xj61TkB/7Z3PegE6c3qd99Z330O6taFjXPtsf2gY/Whv3od3Cy8iPiNBLtlmDmrv+5g1ritNO\n7BEcSPKtCuKwIouIqXDfkO4tOd7m3Pya1i/guKKWnqahc8CdeawmxXedeTTHdmrGJYOdNc+N9JGe\n1KtNWuRyNBCopLPLJscaeCuQk2KfMUc5bz4ar1jl004d3zX+C1vPts7qGZwa1KVFdSsWx3UPLhkc\ncP6pbs0z8sjgJq5jj21f/fgnAzu5cAT78wtdWmWT03FaFJgITwOBiNwiIktFZImIvCIi9UWkq4jM\nEpFVIjJJRLJ7RKkcFKsNv91P4oObR0R9TbwjUF4wyI0fr09gMcR/rh8W8c403kvZS1cdz3f3BQ8J\nEat4JrTCdki32t8lf3ff6UyaMMRxxXo8leOh52W3/uWrjq9+7jQQuBkvrraKZK4b1Z2zQjrMXR1Q\nXPPHc45h2b3B6Y1XpJv+WOez9I+nUeig30yiPAsEItIRuBEoNsb0AfKAS4AHgceMMT2A7cCVXqXB\nbZVVhqc++Z69Nh3EAn307abqx7PXbPM6WWkn5lzLNt/+ghh1CG60R3dD44BWHYlOIpSfVyesT0T9\ngvh+kvkR2v07Ub8gj3yP6m5i9fUIPXa8OQI38i7+Iji7IrvAzza/jtCgbh71E/gOOj2/0AxBo3rJ\naUXkddFQPtBARPKBhsAGYDTwhrX+BeBcj9PgmqmLN/DgtO94+IPlUbe76l9zqh9f9LevvE6WpxIp\nBjmuqOa1Qk0lawLXLt++klyKcDigyKRD88jZdH/v29oU+TgVGnzs3oviLi3449nRh30IlA692oda\nw3Bcc1J3xvVtH2NrdyTzvCO2Wg1ZEfh7+/OF/bxMUhDPAoExpgx4BPgBXwDYCcwFdhhj/LfU64GM\n6dt94JBv0hi7ISOylV2RzLUjnY1Zf96A4OKZs/tHHq8mHnY/qtOO8a5OYL81WdAjF/ajXr79XeEv\nTiiqLr9PpEzXjSD3xrUnRBwSwutj15a/b0jJGb158rKBMbZ2V6zzduN9cZojCKzg/4mLxZuxeFk0\n1AI4B+gKdAAaAdELDoNfP0FE5ojInPLyco9SWTuBdxK/e30h//qqNFVJ8Vxod3hwficV+t33sm2/\nl3d3/iKExlGy6fXyA4ekyE714iy28kbyo5X/Il6QQFbWrhLYTjKGT7Hj5Sd7MrDGGFNujDkEvAWc\nCDS3iooAOgFldi82xjxjjCk2xhQXFiY4aJWHXp+7nrsnL011MjwzqEsLbjm5F02SVFYZ6v7z+vDe\njcNj/vzjvfg+/VPnd513jTuKG0f3iFoJfqPNMA61kYyOcE6FXrtCh6qYfJ3zPhjPX3Ecf/95sRvJ\nco3Tod/9n0ifjk0ZeERzHnDYdyCwAUTgkDLR3H1mfMNvuMXLX/cPwBARaQjsB8YAc4CZwAXAq8B4\nYLKHafCMMSYtyla9JiLcdHJPJi8oY7dVJBbvDyhUPO/b5cf7xg+atWar8xc5cHof5+XQzRvW5TdR\nhlIe3rN1UKWel5dyL/bt9OMIrVSNZ9KbkUc6GzE1qawTjxV8/eX4IsJbv3Ye/AL7ZTgtXkpVj28v\n6whm4asUngcsto71DHA78BsRWQW0Ap7zKg1uC/wsb3hlPt3ufC9laUmpGFcOf2uQ0C9/w3q+bO/R\n7RMb+Ctd7pojBrpkpsHFgv1UvKuhQ184lcybsFit4JwMi54u39lIPC30M8bcY4zpbYzpY4z5mTGm\nwhiz2hgz2BjTwxhzoTHGWZ4pjRgMUxZtSHUyksvh9/ihn/SlYUA5570Bk5a0blyPN64Zyl8u6e92\n6jIud3ZvjMlccsWrE4bYDvMx49aTgPCLcLS49/lto/jYep2bYgXbaFNj1uzEpcR4JDUFvxlo8+4D\nlG7dG3H9oZCJZrJN4Pc42jX3ouM6M7t0m/Ua4ZgOwV31i2s5TEDs31HqIkFoEHLym+/YPLunznSq\necO6QcNf+BW1ct7T3K9zLedGTjRTFW2aTr9U95yOJR2aAWSEwffP4MmZ30dc/8B730Vclw3OD+hm\nb4xhdG8HZb4B3/1ov4NLjutsuzxSj0qnv6k6ktgFt32z+ratpmJxEpLcysGM7dPOnR3FKbCPiBf8\nb7u/jigRZyapX0I06R0GNEfgmqU/ZvccxL8e2Z2qKsOfp68A4O8/L6ayytDrrvfDto3nIrf8f0+3\nbZY37ebhQWPmR/LkZQO57uV5tuuW/+8ZCf0AP79tVNLzGfHeOF4cIYjGozYjeUabntINIhLxuwHx\n5f+euGSAbVFucutykniwWtBAUAvTlmxMdRKSTkSC2pHn1ZGYoyY6+e5H6qCVX6dO0BAEgeW0gfv1\nzxJmdy2LNWxFLLGGX0iHH7erlcVx7CoZp2733ajNcaON5lrbfcYrpyuLs9U+q6dpoAyrq6wVfzln\nbapD4r/pjP6Cv142gD4dm1anKdPe/0TTe2KPVhGnm4zk6hHdwmYRq61UBcF0/5x/e6r9XBXpcNMQ\njeYIlGN51cMVR48Egf0M4v0BRO57EHwJOLNvB87s24EZyzZFeEV6S3RilZeuijyJSyR3jD0qoWMG\nSvfKz1Q5p39HHvlwRdjydH+7NEfgklwYZbSR1aHIaZGLm8UWgdJhIo9EJVps5abIISnymlR9Am4e\n1+1ZzqJJp8/bjuYIslynFg1Yv32/K/s6b2BHynbsD5pa7+mfDqJJ/Xwuf3ZWzYYOfl83jekZV7oC\ng0pXm0nU/T/qxy7uR3cHlcx2pt08nIXrdtTqtfE6qVfwsCl9OjZlSdmusO1evPJ4fvrcrLDl3gi+\nzKZ13wwXEuffRTLu1geE9ML+8JYRzF273fsDO6SBIIaqKqcDKqSnW07uxa2vL3RlXwV5dbglZL7e\n0/u0C5vZyv8s2u8rdD9O/Xxol+CK45CDhI54Go/e7ZoGzeXrVG2+IaEVmF1bN7YNBKHzEydTtLNK\n96KOVHE63HSvtk3o1bZ2vaq9kN75lTRwzpP/pXsGDyWRyh+sSPLuKjM5WKeaf8iP5iHj3PhzXnVt\n52jO/khQFGEu6NpI93dLcwQxLC7L7v4Bbgj9ktuVvboVkMJ78ab7Tyz93X3W0Zw/sGNYkdovT+zK\n3LXbGW0zYFyqbjC8qHeK9B1657oT2bDzgDvHSPOvqQYClbDQL7mJsNzNY4RKRXm2m0EoldeJevl5\nDOoSeegPu/c+1de1ZHzckYa/iCZSoPKq4YRbtGgoy6W0aAihc0vfEA/n9nc2Ed2Fxb6esoWNg2f5\nGniEb0iDsKEt0vv3lRVsA0GaX9ic0OLEGhoIcsjCu08FfBOkr7r/DNf2G3pRCLw7b9OkPqvuP4Of\nD3U2ZszVI7qx6v4zwsZl79OxGavuP4NREcY4ypYfdTq11PFXgtvlfDI/DNRwNefq3q6SSouGosi2\nKSjzrOEYBIk5fEIiQouG4jmWiJCfZ/9zstuPf8tktgkP5cah0/EGu8pJ868kc7cfgYs7y3AaCCIw\nxmTFFJQje9XcQafR79k18RZRPHpRPyYv+NGlY7uyG1vXj+rB3oOHvTuAA/7gmo3fGxVMA0EE2XC3\ncM1J3cOaBCZDKu/OYzl/YKegIbXT1W9Pizw1ZrJlQ31AsmTqW+Uozy4ib4nIOBHROoUMUtsvZW2H\ncGhUN3i0yGy/gPiHDWhszVfsHy0z9H3IVHWrzy/9zseNe43M7irqLqcX9v8DLgNWishEEUmf2xWP\nZMtXxO5iHOv6/MHNI+I+zsTzj+U/NwwDkjzOu/U/FZmQ44paUHJGbx78SV8ATj26Lb877Uh+P869\nwd0A/u/yga7uz6lTj2nH7047kjsDBqvzdzLLi1CP4zWv7y2m3DCMxxOYSjVT+7U4KhoyxnwEfCQi\nzYBLrcfrgL8DLxpjDnmYxqQxxlBxuIr6BXkcjjHCZiZyeq3s0Sb+sXouGRwwvLF/DJe49xK/1Pac\nFq45qXv18zp1hOtG9Uhon3Z3qWOPbU/zhgXs2Jfcn1mezfl0btmQNVsiT9ma6fp0bEafjs1ib5hl\nHBf1iEgr4BfAVcB84HFgIDBhYrXIAAAXbElEQVTdk5SlwN8+W03vP0xj654Kxj7+eaqTk7BI18hk\nXTuzvGQoqdKt2iUbPtqaQeey4WwS4yhHICJvA0cC/wbOMsb4532bJCJzvEpcsr0zvwyATbsq+L48\ne+96vJaKslct780t8X7eX9w+KuIcCm6GgUyNKU5bDT1hjJlpt8IYU+xiepJu484D7Nx/iCPbNeG7\njbsB+PDb7JiKMmzohyTdVlbfaSXhvtF/jHS7Y45XrHcqUy8wbqvtd6pTC/cGkMtGTouGjhaR6gG1\nRaSFiPzaozQl1ZAHZnDaXz5j0fqacej/8tHKFKbIPcN7Ftou92eFR/SyXx9rnVPJuHj5j5HpgSBT\npLppcMcWviFLLhzUOaXpsDOmd5uMLTJzmiP4lTHmSf8TY8x2EfkVvtZEWWHr3oOpToLrhnRrFfQ8\n9Cf8whXHAdD1jvBhtv3rVHrQQOfTslFd1jwwNtXJCONPU/nuihSnpHacBoI8ERFj3Q6ISB4Q37B8\nae6pmd+nOglJ479riVZJlkgFml60ai/d37t0qFh1Ow1u7C4d3pdEOC0amoavYniMiIwBXrGWRSQi\nR4rIgoC/XSJys4i0FJHpIrLS+t8i0ZNww+zS7Jpz+IlLB4Qta1w3n6HdWvH/LgteF9hu+pSj2yZ8\n7FtP7cUxHZomZXat6n4EGV5ZHOtCki7XmVQXDaU9Fz6nk49qy18vC//9eslpjuB24GrgWuv5dODZ\naC8wxiwH+kN1DqIMeBsoAWYYYyaKSIn1/Pb4k66iGdunXdiyOnWEVyYMCVt+Tv+OPPv5GhaX7eT6\nBNvBA/Rs24SpNw5PeD+OpMkFMtdk+h0wpG9Qe3Z88tvfOO1QVgU8Zf3Vxhjge2PMWhE5BxhpLX8B\n+IQUBYKbX52fisMqFaZJ/eBhKpT3GlvveYMC997zrO5ZLCI9gQeAo4HqGUOMMd0cHucSfMVJAG0D\n+iFsBBIvi6ild1wahTIdZcMdWzzS9ObOsdtP702H5g04wyYnp7xxw+ieNK5XwAWDvBuEcPotI/h2\nwy7P9u8Wp3UE/8SXGzgMjAL+Bbzo5IUiUhc4G3g9dJ1V+Wz7ExaRCSIyR0TmlJeXO0ymc3sqUjvE\nb7rJ1LhR3Y8gxelIVKN6+VxzUnfq1HLAPxW/+gV5XDuyuydzc+Rbn2PPtk04x+HsfKnk9B1oYIyZ\nAYgxZq0x5n+AcQ5fewYwzxizyXq+SUTaA1j/N9u9yBjzjDGm2BhTXFiYeJv2QEvKdtLnng9c3We2\nyLQLamETX+O1Y3NwfBiVfjL1hsppZXGFNQT1ShG5Hl/Fr9ORyS6lplgI4F1gPDDR+j/Z4X5cs/TH\nnck+pPJIjzZNmHLDMI5s1yTVSVGqWqbdUDnNEdwENARuBAYBP8V3EY9KRBoBpwBvBSyeCJwiIiuB\nk63nymUZemNSK306NqueG0CpVMrU313MHIHV9PNiY8xvgT3AFU53bozZC7QKWbYVXysilUYy9Quc\naY5q35SNO/enOhkJi/R9OW9AR962Bm9UmSPmbZQxphIYloS0JE06NPEqnei0iiW50rVtdbZ4/6bh\nzL/71FQnI2GRviWPXdw/bb/byZRpvyOndQTzReRdfC1/qsdnNsa8FfklKpUytdJKqUyWqc22nQaC\n+sBWYHTAMkNw2b/KApn6Rc52/3f5QJ75bDXNGhSkOikqCzntWey4XkBltkzL0uaKE7q35oTu3o/d\n5JTeLtjL1PfFac/if2JTLGiM+aXrKfLIjGWb+O3rC/nqDq2nttOyka89vra+USr3OP3VTwGmWn8z\ngKb4WhBljD+9t4zt+w6xbtu+VCclYc/8bFDMbeIt4nn0ov7ce84xHNOhaW2TpZSyZFq+2mnR0JuB\nz0XkFeALT1LkEf+F0TehQkqT4kjH5g0o22HfzPDUY9wfj6ZFo7r8fGiR6/tVKpdkahVbbcsBegJt\n3EyI16rHrc+0UK2UyjiZdp1xWkewm+DczkYybA6B6rltMy7TppTKFOnQR6k2nBYNZfxALv4P6IuV\nW6pHBlRKxSfT7nRTJdOKiJzmCM4DPjbG7LSeNwdGGmPe8TJxbvJ/MP87dVlqE+JQpn2RVG7R72d0\nmRYwndYR3OMPAgDGmB3APd4kSSmlMlSGBkingcBuO6e9ktOC9phVyj2ZdseronMaCOaIyKMi0t36\nexSY62XC3JbKMNClVUP+ePYxjrZt1qCAiecfG3fW+/VrhkZc9+RlA/nZkC7x7VApFbdMvd90Gghu\nAA4Ck4BXgQPAdV4lygup/IBuHN2T8ScUOdr2d6cdySWDj4i79cFxRS0jjvo4rm977ju3T1z7Uyqa\nTL3gKXtOWw3tBUo8Tounlv6Y/hNIAzSul1ElbkqpLOAoRyAi062WQv7nLUREJ/112T1nHc3Z/Tqk\nOhlKqVrK1IyS09vP1lZLIQCMMdtFJKN6FmeCK07sWv1Ys94qHWmHzOzktI6gSkSO8D8RkSIyb1wl\npZTyVKa2TnSaI/g98IWIfIov9zMcmOBZqnLMvD+cwqHKqlQnQ6mYMnUIBRWd08riaSJSjO/iPx94\nB8j8GbiTJNZNgn8ugKDXeJQWpRKhRUPZyWll8VX45iG4Ffgt8G/gf7xLVnY6f2DHVCdBKVdozsBe\npr4rTusIbgKOA9YaY0YBA4Ad0V+iQj16UX/H24aWNUbqI6CUUolyGggOGGMOAIhIPWPMd8CR3iVL\nKZXOtIjIXobWFTuuLF5v9SN4B5guItuBtd4lK7uc5sGMYpG8fNXx/GfRj0k7nlIq8zmtLD7Pevg/\nIjITaAZM8yxVWaZRLXoL1/bG4oQerTmhR+tavlopZ7SOILvEfYUyxnzqdFsrF/Es0Adfv4NfAsvx\njVlUBJQCFxljtsebDqWUSjeZGiBrO2exU48D04wxvYF+wDJ8YxbNMMb0xNcSKaPHMErEx7eexHPj\ni+1XZub3SWU5HX46O3k2wpmINANGAL8AMMYcBA6KyDnASGuzF4BPyLD5j93SrbAx3QobpzoZSsUt\nUytFvZap74uXOYKuQDnwTxGZLyLPikgjoK0xZoO1zUagrYdpAGD2mm1eH8J1dt+nboWNkp4Opexo\nziC7eBkI8oGBwFPGmAFA2FDWxhhDhDGLRGSCiMwRkTnl5eUJJWTZBneHoO7X2TcQa8fmDWzXn9ij\nlavH83v3+mF8dcdoT/atlBOZeserovMyEKwH1htjZlnP38AXGDaJSHsA6/9muxcbY54xxhQbY4oL\nCwsTSojb4/g0sVoBtWtW33Z926b2yxPVuF4+7ZvZBx+lkkFzAtnJs0BgjNkIrBMRf8ezMcC3wLvA\neGvZeGCyV2nwe/iD5a7u76fWtI9Htmtiu76DCxfrWKMYXlTcifoFvo/vmpO6J3w8peKhOYPs4vV0\nWDcAL4lIXWA1cAW+4POaiFyJr1PaRR6ngYrD7uYITu/TjtKJ43hs+grb9Y3r51M6cRxFJVNdPW6g\nhy7ox0MX9PNs/0qp+GVqgPQ0EBhjFgB27SPHeHlcpZRSznndjyCreRn9M/TGQmW5B84/lrP7deC4\nopapTopykc6U7gE3LuKZmsVU2a1Lq0Y8cemAVCcjbWnPYqWUUhlJA4FSSrkkU3PyGghcMPLI4H4O\nbnwZMjWLqZTKPBoI4nR815pKMv/FWjvZKKUymQaCEEe1bxp1/W2n68RsSil7mZqPz+pWQ5t2HeC7\njbtd3Wd+nfDY6UWGIFPLGpVSmSerA8HZf/2CTbsq4npNnRgXYLsLdNdWDfnM4f57tW1MUSvno4g2\nrpfP0R2i51KUUukh1tAw6SqrA0G8QSBQg4I89h+qdLRt0wYFvHzV8Vz27KyY2354y0lxpeO1q4dq\nIFBKeUrrCELECuiBrXn82xpDUOGgmy1+jCcFT0opVSOrcwS1Ud0SKM4L8OCilpx+TDu27q3g0uOP\nSDwdGZrFVCqXZeqvVgNBnCJdn/Pz6vD0zwYlNzFKKeUCLRoKkW434tpHQanMkW7XD6c0EISI9Tkm\n64PO0O+TUioDaSBIgP9irRW6SqlMpoEgVIRb/vbW/MStG9dzvKtGdfNcSZJSKjNkaiMPrSwOUX2X\nH3KTf9vpR3J811ZxTUz/9Z1jOFxZu9xCUNNUpZTykAaCEP4LcGhgryNCh+YNbLeNpEn9goTToZRS\nXtOioQhC78STneW79qQeAHRp3TCpx1VK5R7NEYQIvdw3rpfPnorDUV/jRfHNuL7tGdd3nPs7Vkqp\nEJojCJGplT1KKVVbGghiMFpbq5TKchoIQkTKD9gt19yDUiobaCCIQfMDSqlsp4EgRHX7/QjL7Wiw\nUEplMg0EISLNJeDmHANKKZVOPA0EIlIqIotFZIGIzLGWtRSR6SKy0vrfwss0OBE0YX3I9V7ripVS\n2S4ZOYJRxpj+xphi63kJMMMY0xOYYT1PijZN7McJevvXJ0R8jX9AOa0XVkplq1QUDZ0DvGA9fgE4\nN1kHLsizP936BTWDw4Ve7/05gmiT2muuQSmVybwOBAb4UETmisgEa1lbY8wG6/FGoK3dC0VkgojM\nEZE55eXlriTmN6f0irnNNSd1B+Codk2AwIt8eCTQXIJSKht4HQiGGWMGAmcA14nIiMCVxtdby/Z+\n2hjzjDGm2BhTXFhY6EpixvVtH3ObUb3bUDpxHM0a1g1arhd9pVS28jQQGGPKrP+bgbeBwcAmEWkP\nYP3f7GUaElVdR5DidCillFc8G3RORBoBdYwxu63HpwL3Au8C44GJ1v/JXqUhPE2R1025YRjTv91U\ns631X8v/lVLxuPWUXozo5U4pRrJ4OfpoW+BtaxiGfOBlY8w0EfkGeE1ErgTWAhd5mIYg0foC9OnY\njD4dm1U/D+9QFvm1OlWlUsrvhjE9U52EuHkWCIwxq4F+Nsu3AmO8Om40odfylo3qsm3vwaiv8V/i\n7VoNFVrTVhbGMX2lUkqlm5yajyD0Wv7ejcNZs2Vv1NdUmcj9CH4ysBP1C/IYe2zsSmillEpXORUI\nQrVrVp92zaLPQeyvI7ArVqpTRzirXwcvkqaUUkmTU2MNBZbzN6nvLAYO79kagCNa6ZSRSqnslFM5\ngsB7+tl3nuzoNb8c1pVHL+pPYYThKZRSKtPlWI6g5nGDunmRNwx8DWgQUEpltRwLBNotTCmlQuVU\nIFBKKRVOA4FSSuW4nKosBvjbzwZx4FBlzO2Mji2hlMoRORcITjumXVzba72CUirbadFQDJozUEpl\nOw0ESimV4zQQxKBFQ0qpbKeBQCmlcpwGAqWUynEaCJRSKsdldSDo16lZ7I2UUirHZXUguG5Uj1Qn\nQSml0l5WBwI3egBomyGlVLbL7kCgfcGUUiqmrA4ESimlYsvyQKBZAqWUiiXLA4FSSqlYsjoQJFJH\noPULSqlckdWBoGfbxgnvQ4caUkplu6yej6BHmyYsvOdUGtbN41BlVa32oTkDpVS28zxHICJ5IjJf\nRKZYz7uKyCwRWSUik0SkrpfHb9aggIK8OjSsm9UxTymlai0ZRUM3AcsCnj8IPGaM6QFsB65MQhpq\nTYuGlFLZztNAICKdgHHAs9ZzAUYDb1ibvACc62UalFJKRed1juAvwG2Av4C+FbDDGHPYer4e6Gj3\nQhGZICJzRGROeXm5x8kMV7/A99bU0SyBUirLeRYIRORMYLMxZm5tXm+MecYYU2yMKS4sLHQ5dbFN\n/ElfrhvVnaHdWiX92EoplUxe1qCeCJwtImOB+kBT4HGguYjkW7mCTkCZh2motdaN6/G703qnOhlK\nKeU5z3IExpg7jDGdjDFFwCXAx8aYy4GZwAXWZuOByV6lQSmlVGyp6FB2O/AbEVmFr87guRSkQSml\nlCUpjeuNMZ8An1iPVwODk3FcpZRSsWX1EBNKKaVi00CglFI5TgOBUkrlOA0ESimV4zQQKKVUjhOT\nAeMsi0g5sLaWL28NbHExOZlAzzk36Dlnv0TPt4sxJubQDBkRCBIhInOMMcWpTkcy6TnnBj3n7Jes\n89WiIaWUynEaCJRSKsflQiB4JtUJSAE959yg55z9knK+WV9HoJRSKrpcyBEopZSKIqsDgYicLiLL\nRWSViJSkOj21JSL/EJHNIrIkYFlLEZkuIiut/y2s5SIiT1jnvEhEBga8Zry1/UoRGZ+Kc3FKRDqL\nyEwR+VZElorITdbyrD1vEakvIrNFZKF1zn+0lncVkVnWuU0SkbrW8nrW81XW+qKAfd1hLV8uIqel\n5oycE5E8EZkvIlOs51l9ziJSKiKLRWSBiMyxlqXuu22Myco/IA/4HugG1AUWAkenOl21PJcRwEBg\nScCyh4AS63EJ8KD1eCzwPiDAEGCWtbwlsNr638J63CLV5xblnNsDA63HTYAVwNHZfN5W2htbjwuA\nWda5vAZcYi1/GrjWevxr4Gnr8SXAJOvx0db3vR7Q1fod5KX6/GKc+2+Al4Ep1vOsPmegFGgdsixl\n3+1szhEMBlYZY1YbYw4CrwLnpDhNtWKM+QzYFrL4HOAF6/ELwLkBy/9lfL7GNyNce+A0YLoxZpsx\nZjswHTjd+9TXjjFmgzFmnvV4N7AM3/zWWXveVtr3WE8LrD8DjAbesJaHnrP/vXgDGCMiYi1/1RhT\nYYxZA6wijYd+F5FOwDjgWeu5kOXnHEHKvtvZHAg6AusCnq+3lmWLtsaYDdbjjUBb63Gk887Y98PK\n/g/Ad4ec1edtFZEsADbj+2F/D+wwvqldITj91edmrd+Jb7KnjDpn4C/AbUCV9bwV2X/OBvhQROaK\nyARrWcq+20mZmEZ5yxhjRCQrm3+JSGPgTeBmY8wu382fTzaetzGmEugvIs2Bt4GsnjhbRM4ENhtj\n5orIyFSnJ4mGGWPKRKQNMF1EvgtcmezvdjbnCMqAzgHPO1nLssUmK3uI9X+ztTzSeWfc+yEiBfiC\nwEvGmLesxVl/3gDGmB345vceiq8owH/TFpj+6nOz1jcDtpJZ53wicLaIlOIrvh0NPE52nzPGmDLr\n/2Z8AX8wKfxuZ3Mg+AboabU+qIuvYundFKfJTe8C/lYC44HJAct/brU0GALstLKbHwCnikgLqzXC\nqdaytGSV+z4HLDPGPBqwKmvPW0QKrZwAItIAOAVf3chM4AJrs9Bz9r8XFwAfG18t4rvAJVYLm65A\nT2B2cs4iPsaYO4wxnYwxRfh+ox8bYy4ni89ZRBqJSBP/Y3zfySWk8rud6tpzL//w1bavwFfO+vtU\npyeB83gF2AAcwlcOeCW+ctEZwErgI6Clta0AT1rnvBgoDtjPL/FVoq0Crkj1ecU452H4ylEXAQus\nv7HZfN5AX2C+dc5LgLut5d3wXdRWAa8D9azl9a3nq6z13QL29XvrvVgOnJHqc3N4/iOpaTWUteds\nndtC62+p/9qUyu+29ixWSqkcl81FQ0oppRzQQKCUUjlOA4FSSuU4DQRKKZXjNBAopVSO00CgVBQi\ncrOINEx1OpTykjYfVSoKq8drsTFmS6rTopRXNEeglMXq8TlVfPMBLBGRe4AOwEwRmWltc6qIfCUi\n80TkdWssJP/48g9ZY8zPFpEe1vILrX0tFJHPUnd2SkWmgUCpGqcDPxpj+hlj+uAbFfNHYJQxZpSI\ntAbuAk42xgwE5uAbR99vpzHmWOCv1msB7gZOM8b0A85O1okoFQ8NBErVWAycIiIPishwY8zOkPVD\n8E2A8l9rqOjxQJeA9a8E/B9qPf4v8LyI/ArfZElKpR0dhlopizFmhTUN4Fjgf0VkRsgmgm8ikEsj\n7SL0sTHmGhE5Ht/EK3NFZJAxZqvbaVcqEZojUMoiIh2AfcaYF4GH8U0PuhvfVJkAXwMnBpT/NxKR\nXgG7uDjg/1fWNt2NMbOMMXcD5QQPG6xUWtAcgVI1jgUeFpEqfCO9XouviGeaiPxo1RP8AnhFROpZ\nr7kL3wi3AC1EZBFQAfhzDQ+LSE98uYkZ+EacVCqtaPNRpVygzUxVJtOiIaWUynGaI1BKqRynOQKl\nlMpxGgiUUirHaSBQSqkcp4FAKaVynAYCpZTKcRoIlFIqx/1/PAtFx+TDx6EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"3HiddenL2Optimization\"\n",
    "\n",
    "batch_size = 128\n",
    "num_steps = 5000\n",
    "report_every = 250\n",
    "starting_learning_rate = 0.2\n",
    "\n",
    "hidden_layer_1_size = 2048\n",
    "hidden_layer_2_size = 1024\n",
    "hidden_layer_3_size = 512\n",
    "\n",
    "hidden_layer_1_stddev = np.sqrt(2.0 / input_size) \n",
    "hidden_layer_2_stddev = np.sqrt(2.0 / hidden_layer_1_size)\n",
    "hidden_layer_3_stddev = np.sqrt(2.0 / hidden_layer_2_size)\n",
    "output_layer_stddev = np.sqrt(2.0 / hidden_layer_3_size)\n",
    "\n",
    "hidden_layer_1_keep_prob = 0.5\n",
    "hidden_layer_2_keep_prob = 0.7\n",
    "hidden_layer_3_keep_prob = 0.8\n",
    "\n",
    "beta_1 = 0.001\n",
    "beta_2 = 0.001\n",
    "beta_3 = 0.001\n",
    "beta_4 = 0.001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, input_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "  # first hidden layer\n",
    "  hidden_layer_1_weights = tf.Variable(tf.truncated_normal(\n",
    "    [input_size, hidden_layer_1_size], stddev=hidden_layer_1_stddev))\n",
    "  hidden_layer_1_biases = tf.Variable(tf.zeros([hidden_layer_1_size]))\n",
    "  hidden_layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_layer_1_weights) + hidden_layer_1_biases)\n",
    "  \n",
    "  # second hidden layer\n",
    "  hidden_layer_2_weights = tf.Variable(tf.truncated_normal(\n",
    "    [hidden_layer_1_size, hidden_layer_2_size], stddev=hidden_layer_2_stddev))\n",
    "  hidden_layer_2_biases = tf.Variable(tf.zeros([hidden_layer_2_size]))\n",
    "  hidden_layer_2 = tf.nn.relu(tf.matmul(hidden_layer_1, hidden_layer_2_weights) + hidden_layer_2_biases)\n",
    "  \n",
    "  # third hidden layer\n",
    "  hidden_layer_3_weights = tf.Variable(tf.truncated_normal(\n",
    "    [hidden_layer_2_size, hidden_layer_3_size], stddev=hidden_layer_3_stddev))\n",
    "  hidden_layer_3_biases = tf.Variable(tf.zeros([hidden_layer_3_size]))\n",
    "  hidden_layer_3 = tf.nn.relu(tf.matmul(hidden_layer_2, hidden_layer_3_weights) + hidden_layer_3_biases)\n",
    "  \n",
    "  # output layer\n",
    "  output_weights = tf.Variable(tf.truncated_normal(\n",
    "    [hidden_layer_3_size, num_labels], stddev=output_layer_stddev))\n",
    "  output_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  logits = tf.matmul(hidden_layer_3, output_weights) + output_biases\n",
    "\n",
    "  # calculate the loss with regularization\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels))\n",
    "  loss += (beta_1 * tf.nn.l2_loss(hidden_layer_1_weights) +\n",
    "           beta_2 * tf.nn.l2_loss(hidden_layer_2_weights) +\n",
    "           beta_3 * tf.nn.l2_loss(hidden_layer_3_weights) +\n",
    "           beta_4 * tf.nn.l2_loss(output_weights))\n",
    "  \n",
    "  # learn with exponential rate decay.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  learning_rate = tf.train.exponential_decay(starting_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # train prediction\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "  # setup validation prediction step.\n",
    "  validation_hidden_layer_1 = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_layer_1_weights) + hidden_layer_1_biases)\n",
    "  validation_hidden_layer_2 = tf.nn.relu(tf.matmul(validation_hidden_layer_1, hidden_layer_2_weights) + hidden_layer_2_biases)\n",
    "  validation_hidden_layer_3 = tf.nn.relu(tf.matmul(validation_hidden_layer_2, hidden_layer_3_weights) + hidden_layer_3_biases)\n",
    "  validation_logits = tf.matmul(validation_hidden_layer_3, output_weights) + output_biases\n",
    "  validation_prediction = tf.nn.softmax(validation_logits)\n",
    "\n",
    "  # and setup the test prediction step.  \n",
    "  test_hidden_layer_1 = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_layer_1_weights) + hidden_layer_1_biases)\n",
    "  test_hidden_layer_2 = tf.nn.relu(tf.matmul(test_hidden_layer_1, hidden_layer_2_weights) + hidden_layer_2_biases)\n",
    "  test_hidden_layer_3 = tf.nn.relu(tf.matmul(test_hidden_layer_2, hidden_layer_3_weights) + hidden_layer_3_biases)\n",
    "  test_logits = tf.matmul(test_hidden_layer_3, output_weights) + output_biases\n",
    "  test_prediction = tf.nn.softmax(test_logits)\n",
    "  \n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "accuracy_over_time = []\n",
    "steps = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\\n\")\n",
    "\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    accuracy_over_time.append(accuracy(predictions, batch_labels))\n",
    "    steps.append(step)\n",
    "    \n",
    "    if (step % report_every == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\\n\" % accuracy(validation_prediction.eval(), valid_labels))\n",
    "  \n",
    "  print(\"  Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "  steps, accuracy_over_time = accuracy_averaged(steps, accuracy_over_time)\n",
    "  plt.plot(steps, accuracy_over_time)\n",
    "  plt.xlabel(\"steps\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.show()\n",
    "\n",
    "  # Save the final model\n",
    "  model_folder = trained_models_folder + model_name\n",
    "  makedir(model_folder)\n",
    "  saver.save(session, model_folder + \"/\" + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### 3 hidden layers with dropout and L2 optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "\n",
      "Minibatch loss at step 0: 1.741124\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 50.8%\n",
      "\n",
      "Minibatch loss at step 250: 1.625282\n",
      "Minibatch accuracy: 39.8%\n",
      "Validation accuracy: 53.7%\n",
      "\n",
      "Minibatch loss at step 500: 1.523569\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 54.9%\n",
      "\n",
      "Minibatch loss at step 750: 1.438215\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 54.9%\n",
      "\n",
      "Minibatch loss at step 1000: 1.355699\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 56.5%\n",
      "\n",
      "Minibatch loss at step 1250: 1.286745\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 57.2%\n",
      "\n",
      "Minibatch loss at step 1500: 1.237225\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 55.3%\n",
      "\n",
      "Minibatch loss at step 1750: 1.176625\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 58.2%\n",
      "\n",
      "Minibatch loss at step 2000: 1.155388\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 57.7%\n",
      "\n",
      "Minibatch loss at step 2250: 1.055303\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 60.5%\n",
      "\n",
      "Minibatch loss at step 2500: 1.020376\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 60.2%\n",
      "\n",
      "Minibatch loss at step 2750: 1.008293\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 64.1%\n",
      "\n",
      "Minibatch loss at step 3000: 0.924969\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 64.7%\n",
      "\n",
      "Minibatch loss at step 3250: 0.919889\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 62.0%\n",
      "\n",
      "Minibatch loss at step 3500: 0.851584\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 67.6%\n",
      "\n",
      "Minibatch loss at step 3750: 0.851918\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 68.3%\n",
      "\n",
      "Minibatch loss at step 4000: 0.747729\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 70.3%\n",
      "\n",
      "Minibatch loss at step 4250: 0.852868\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 71.9%\n",
      "\n",
      "Minibatch loss at step 4500: 0.862516\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 71.6%\n",
      "\n",
      "Minibatch loss at step 4750: 0.782874\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 71.5%\n",
      "\n",
      "Minibatch loss at step 5000: 0.753765\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 77.5%\n",
      "\n",
      "Minibatch loss at step 5250: 0.729667\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 77.6%\n",
      "\n",
      "Minibatch loss at step 5500: 0.702846\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 71.8%\n",
      "\n",
      "Minibatch loss at step 5750: 0.694429\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.9%\n",
      "\n",
      "Minibatch loss at step 6000: 0.742005\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 79.2%\n",
      "\n",
      "Minibatch loss at step 6250: 0.689912\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 75.8%\n",
      "\n",
      "Minibatch loss at step 6500: 0.578014\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "\n",
      "Minibatch loss at step 6750: 0.728639\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 82.7%\n",
      "\n",
      "Minibatch loss at step 7000: 0.635579\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 82.1%\n",
      "\n",
      "Minibatch loss at step 7250: 0.700387\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.9%\n",
      "\n",
      "Minibatch loss at step 7500: 0.610629\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.9%\n",
      "\n",
      "Minibatch loss at step 7750: 0.807442\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 79.7%\n",
      "\n",
      "Minibatch loss at step 8000: 0.571236\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 83.6%\n",
      "\n",
      "Minibatch loss at step 8250: 0.621430\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 83.8%\n",
      "\n",
      "Minibatch loss at step 8500: 0.577546\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.9%\n",
      "\n",
      "Minibatch loss at step 8750: 0.677630\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 84.9%\n",
      "\n",
      "Minibatch loss at step 9000: 0.563777\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.0%\n",
      "\n",
      "Minibatch loss at step 9250: 0.586335\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 86.2%\n",
      "\n",
      "Minibatch loss at step 9500: 0.607303\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 84.9%\n",
      "\n",
      "Minibatch loss at step 9750: 0.617514\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 85.9%\n",
      "\n",
      "Minibatch loss at step 10000: 0.603792\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 87.0%\n",
      "\n",
      "Minibatch loss at step 10250: 0.534390\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 84.6%\n",
      "\n",
      "Minibatch loss at step 10500: 0.546466\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.6%\n",
      "\n",
      "Minibatch loss at step 10750: 0.604303\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 86.7%\n",
      "\n",
      "Minibatch loss at step 11000: 0.519864\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.8%\n",
      "\n",
      "Minibatch loss at step 11250: 0.470971\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.7%\n",
      "\n",
      "Minibatch loss at step 11500: 0.522574\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 87.1%\n",
      "\n",
      "Minibatch loss at step 11750: 0.541554\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.6%\n",
      "\n",
      "Minibatch loss at step 12000: 0.590544\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 87.1%\n",
      "\n",
      "Minibatch loss at step 12250: 0.651195\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 83.7%\n",
      "\n",
      "Minibatch loss at step 12500: 0.622029\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "\n",
      "Minibatch loss at step 12750: 0.471210\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.7%\n",
      "\n",
      "Minibatch loss at step 13000: 0.531098\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.8%\n",
      "\n",
      "Minibatch loss at step 13250: 0.611639\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 87.3%\n",
      "\n",
      "Minibatch loss at step 13500: 0.513159\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.6%\n",
      "\n",
      "Minibatch loss at step 13750: 0.638651\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 86.8%\n",
      "\n",
      "Minibatch loss at step 14000: 0.561742\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 87.5%\n",
      "\n",
      "Minibatch loss at step 14250: 0.592575\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 84.4%\n",
      "\n",
      "Minibatch loss at step 14500: 0.702443\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 87.2%\n",
      "\n",
      "Minibatch loss at step 14750: 0.534162\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.5%\n",
      "\n",
      "  Test accuracy: 87.7%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDXGaCJRSaojTRKCUUkOcJgKllBri/j/c9Hw70yUhFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"3HiddenDropoutAndL2Optimization\"\n",
    "\n",
    "batch_size = 128\n",
    "num_steps = 15000\n",
    "report_every = 250\n",
    "starting_learning_rate = 0.2\n",
    "\n",
    "layer_sizes = {\n",
    "  \"1\": 1024,\n",
    "  \"2\": 256,\n",
    "  \"3\": 32\n",
    "}\n",
    "\n",
    "stddevs = {\n",
    "  \"1\": np.sqrt(2.0 / input_size) ,\n",
    "  \"2\": np.sqrt(2.0 / layer_sizes[\"1\"]),\n",
    "  \"3\": np.sqrt(2.0 / layer_sizes[\"2\"]),\n",
    "  \"out\": np.sqrt(2.0 / layer_sizes[\"3\"]),\n",
    "}\n",
    "\n",
    "keep_probs = {\n",
    "  \"1\": 0.4,\n",
    "  \"2\": 0.6,\n",
    "  \"3\": 0.8,\n",
    "}\n",
    "\n",
    "betas = {\n",
    "  \"1\": 0.001,\n",
    "  \"2\": 0.001,\n",
    "  \"3\": 0.001,\n",
    "  \"4\": 0.001,\n",
    "}\n",
    "\n",
    "weights = {}\n",
    "biases = {}\n",
    "layers = {}\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, input_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "  # first hidden layer\n",
    "  weights[\"1\"] = tf.Variable(tf.truncated_normal(\n",
    "    [input_size, layer_sizes[\"1\"]], stddev=stddevs[\"1\"]))\n",
    "  biases[\"1\"] = tf.Variable(tf.zeros([layer_sizes[\"1\"]]))\n",
    "  layers[\"1\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(tf_train_dataset, weights[\"1\"]) + biases[\"1\"]),\n",
    "    keep_probs[\"1\"])\n",
    "  \n",
    "  # second hidden layer\n",
    "  weights[\"2\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"1\"], layer_sizes[\"2\"]], stddev=stddevs[\"2\"]))\n",
    "  biases[\"2\"] = tf.Variable(tf.zeros([layer_sizes[\"2\"]]))\n",
    "  layers[\"2\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(layers[\"1\"], weights[\"2\"]) + biases[\"2\"]),\n",
    "    keep_probs[\"2\"])\n",
    "  \n",
    "  # third hidden layer\n",
    "  weights[\"3\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"2\"], layer_sizes[\"3\"]], stddev=stddevs[\"3\"]))\n",
    "  biases[\"3\"] = tf.Variable(tf.zeros([layer_sizes[\"3\"]]))\n",
    "  layers[\"3\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(layers[\"2\"], weights[\"3\"]) + biases[\"3\"]), \n",
    "    keep_probs[\"3\"])\n",
    "  \n",
    "  # output layer\n",
    "  weights[\"out\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"3\"], num_labels], stddev=stddevs[\"out\"]))\n",
    "  biases[\"out\"] = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # logit layer\n",
    "  logits = tf.matmul(layers[\"3\"], weights[\"out\"]) + biases[\"out\"]\n",
    "\n",
    "  # calculate the loss with regularization\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels))\n",
    "  loss += (betas[\"1\"] * tf.nn.l2_loss(weights[\"1\"]) +\n",
    "           betas[\"2\"] * tf.nn.l2_loss(weights[\"2\"]) +\n",
    "           betas[\"3\"] * tf.nn.l2_loss(weights[\"3\"]) +\n",
    "           betas[\"4\"] * tf.nn.l2_loss(weights[\"out\"]))\n",
    "  \n",
    "  # learn with exponential rate decay.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  learning_rate = tf.train.exponential_decay(starting_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # train prediction\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "  # setup validation prediction step.\n",
    "  validation_layers = {}\n",
    "  validation_layers[\"1\"] = tf.nn.relu(tf.matmul(tf_valid_dataset, weights[\"1\"]) + biases[\"1\"])\n",
    "  validation_layers[\"2\"] = tf.nn.relu(tf.matmul(validation_layers[\"1\"], weights[\"2\"]) + biases[\"2\"])\n",
    "  validation_layers[\"3\"] = tf.nn.relu(tf.matmul(validation_layers[\"2\"], weights[\"3\"]) + biases[\"3\"])\n",
    "  validation_logits = tf.matmul(validation_layers[\"3\"], weights[\"out\"]) + biases[\"out\"]\n",
    "  validation_prediction = tf.nn.softmax(validation_logits)\n",
    "\n",
    "  # and setup the test prediction step.  \n",
    "  test_layers = {}\n",
    "  test_layers[\"1\"] = tf.nn.relu(tf.matmul(tf_test_dataset, weights[\"1\"]) + biases[\"1\"])\n",
    "  test_layers[\"2\"] = tf.nn.relu(tf.matmul(test_layers[\"1\"], weights[\"2\"]) + biases[\"2\"])\n",
    "  test_layers[\"3\"] = tf.nn.relu(tf.matmul(test_layers[\"2\"], weights[\"3\"]) + biases[\"3\"])\n",
    "  test_logits = tf.matmul(test_layers[\"3\"], weights[\"out\"]) + biases[\"out\"]\n",
    "  test_prediction = tf.nn.softmax(test_logits)\n",
    "  \n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "accuracy_over_time = []\n",
    "steps = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\\n\")\n",
    "\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    accuracy_over_time.append(accuracy(predictions, batch_labels))\n",
    "    steps.append(step)\n",
    "    \n",
    "    if (step % report_every == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\\n\" % accuracy(validation_prediction.eval(), valid_labels))\n",
    "  \n",
    "  print(\"  Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "  steps, accuracy_over_time = accuracy_averaged(steps, accuracy_over_time, 40)\n",
    "  plt.plot(steps, accuracy_over_time)\n",
    "  plt.xlabel(\"steps\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.show()\n",
    "\n",
    "  # Save the final model\n",
    "  model_folder = trained_models_folder + model_name\n",
    "  makedir(model_folder)\n",
    "  saver.save(session, model_folder + \"/\" + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3 Hidden Layers with Dropout no L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "\n",
      "Minibatch loss at step 0: 0.750843\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 48.9%\n",
      "\n",
      "Minibatch loss at step 250: 0.683756\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 56.2%\n",
      "\n",
      "Minibatch loss at step 500: 0.695410\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 55.0%\n",
      "\n",
      "Minibatch loss at step 750: 0.677178\n",
      "Minibatch accuracy: 53.9%\n",
      "Validation accuracy: 57.3%\n",
      "\n",
      "Minibatch loss at step 1000: 0.693074\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 58.3%\n",
      "\n",
      "Minibatch loss at step 1250: 0.667060\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 58.7%\n",
      "\n",
      "Minibatch loss at step 1500: 0.648692\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 62.0%\n",
      "\n",
      "Minibatch loss at step 1750: 0.655185\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 60.1%\n",
      "\n",
      "Minibatch loss at step 2000: 0.634161\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 62.6%\n",
      "\n",
      "Minibatch loss at step 2250: 0.579588\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 63.7%\n",
      "\n",
      "Minibatch loss at step 2500: 0.626193\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 62.8%\n",
      "\n",
      "Minibatch loss at step 2750: 0.581856\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 66.0%\n",
      "\n",
      "Minibatch loss at step 3000: 0.582287\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 68.0%\n",
      "\n",
      "Minibatch loss at step 3250: 0.542716\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 68.7%\n",
      "\n",
      "Minibatch loss at step 3500: 0.559096\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 69.5%\n",
      "\n",
      "Minibatch loss at step 3750: 0.566054\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 70.7%\n",
      "\n",
      "Minibatch loss at step 4000: 0.527203\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 73.0%\n",
      "\n",
      "Minibatch loss at step 4250: 0.492458\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 72.7%\n",
      "\n",
      "Minibatch loss at step 4500: 0.523812\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 74.9%\n",
      "\n",
      "Minibatch loss at step 4750: 0.623995\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.4%\n",
      "\n",
      "Minibatch loss at step 5000: 0.602633\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 77.5%\n",
      "\n",
      "Minibatch loss at step 5250: 0.496253\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.5%\n",
      "\n",
      "Minibatch loss at step 5500: 0.476029\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.1%\n",
      "\n",
      "Minibatch loss at step 5750: 0.440416\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.6%\n",
      "\n",
      "Minibatch loss at step 6000: 0.385266\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 83.8%\n",
      "\n",
      "Minibatch loss at step 6250: 0.450342\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 84.1%\n",
      "\n",
      "Minibatch loss at step 6500: 0.358013\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 84.4%\n",
      "\n",
      "Minibatch loss at step 6750: 0.405858\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 84.9%\n",
      "\n",
      "Minibatch loss at step 7000: 0.350260\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.7%\n",
      "\n",
      "Minibatch loss at step 7250: 0.461494\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 79.4%\n",
      "\n",
      "Minibatch loss at step 7500: 0.341440\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.8%\n",
      "\n",
      "Minibatch loss at step 7750: 0.376924\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.8%\n",
      "\n",
      "Minibatch loss at step 8000: 0.397295\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.6%\n",
      "\n",
      "Minibatch loss at step 8250: 0.298290\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.2%\n",
      "\n",
      "Minibatch loss at step 8500: 0.327851\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "\n",
      "Minibatch loss at step 8750: 0.354463\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.6%\n",
      "\n",
      "Minibatch loss at step 9000: 0.381532\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.0%\n",
      "\n",
      "Minibatch loss at step 9250: 0.376198\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.5%\n",
      "\n",
      "Minibatch loss at step 9500: 0.417011\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 88.1%\n",
      "\n",
      "Minibatch loss at step 9750: 0.297815\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.5%\n",
      "\n",
      "Minibatch loss at step 10000: 0.365545\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.5%\n",
      "\n",
      "Minibatch loss at step 10250: 0.366425\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.7%\n",
      "\n",
      "Minibatch loss at step 10500: 0.379620\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.3%\n",
      "\n",
      "Minibatch loss at step 10750: 0.321982\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.3%\n",
      "\n",
      "Minibatch loss at step 11000: 0.220629\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.3%\n",
      "\n",
      "Minibatch loss at step 11250: 0.300321\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "\n",
      "Minibatch loss at step 11500: 0.318398\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.7%\n",
      "\n",
      "Minibatch loss at step 11750: 0.389510\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 88.7%\n",
      "\n",
      "Minibatch loss at step 12000: 0.305208\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.2%\n",
      "\n",
      "Minibatch loss at step 12250: 0.328217\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.9%\n",
      "\n",
      "Minibatch loss at step 12500: 0.304669\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.9%\n",
      "\n",
      "Minibatch loss at step 12750: 0.314573\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.8%\n",
      "\n",
      "Minibatch loss at step 13000: 0.385077\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.3%\n",
      "\n",
      "Minibatch loss at step 13250: 0.380743\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.9%\n",
      "\n",
      "Minibatch loss at step 13500: 0.360319\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.5%\n",
      "\n",
      "Minibatch loss at step 13750: 0.356186\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.1%\n",
      "\n",
      "Minibatch loss at step 14000: 0.328944\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.9%\n",
      "\n",
      "Minibatch loss at step 14250: 0.366861\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.6%\n",
      "\n",
      "Minibatch loss at step 14500: 0.275750\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.0%\n",
      "\n",
      "Minibatch loss at step 14750: 0.282565\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.9%\n",
      "\n",
      "  Test accuracy: 89.4%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKaX6OU0ESinVz2kiUEqpfu7/A+TbnQyOo10rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"3HiddenWithDropout\"\n",
    "\n",
    "batch_size = 128\n",
    "num_steps = 15000\n",
    "report_every = 250\n",
    "starting_learning_rate = 0.2\n",
    "\n",
    "layer_sizes = {\n",
    "  \"1\": 2048,\n",
    "  \"2\": 1024,\n",
    "  \"3\": 64\n",
    "}\n",
    "\n",
    "stddevs = {\n",
    "  \"1\": np.sqrt(2.0 / input_size) ,\n",
    "  \"2\": np.sqrt(2.0 / layer_sizes[\"1\"]),\n",
    "  \"3\": np.sqrt(2.0 / layer_sizes[\"2\"]),\n",
    "  \"out\": np.sqrt(2.0 / layer_sizes[\"3\"]),\n",
    "}\n",
    "\n",
    "keep_probs = {\n",
    "  \"1\": 0.4,\n",
    "  \"2\": 0.6,\n",
    "  \"3\": 0.8,\n",
    "}\n",
    "\n",
    "betas = {\n",
    "  \"1\": 0.001,\n",
    "  \"2\": 0.001,\n",
    "  \"3\": 0.001,\n",
    "  \"4\": 0.001,\n",
    "}\n",
    "\n",
    "weights = {}\n",
    "biases = {}\n",
    "layers = {}\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, input_size), name=\"dataset\")\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels), name=\"labels\")\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "  # first hidden layer\n",
    "  weights[\"1\"] = tf.Variable(tf.truncated_normal(\n",
    "    [input_size, layer_sizes[\"1\"]], stddev=stddevs[\"1\"]), name=\"weights_1\")\n",
    "  biases[\"1\"] = tf.Variable(tf.zeros([layer_sizes[\"1\"]]), name=\"biases_1\")\n",
    "  layers[\"1\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(tf_train_dataset, weights[\"1\"]) + biases[\"1\"]),\n",
    "    keep_probs[\"1\"])\n",
    "  \n",
    "  # second hidden layer\n",
    "  weights[\"2\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"1\"], layer_sizes[\"2\"]], stddev=stddevs[\"2\"]), name=\"weights_2\")\n",
    "  biases[\"2\"] = tf.Variable(tf.zeros([layer_sizes[\"2\"]]), name=\"biases_2\")\n",
    "  layers[\"2\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(layers[\"1\"], weights[\"2\"]) + biases[\"2\"]),\n",
    "    keep_probs[\"2\"])\n",
    "  \n",
    "  # third hidden layer\n",
    "  weights[\"3\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"2\"], layer_sizes[\"3\"]], stddev=stddevs[\"3\"]), name=\"weights_3\")\n",
    "  biases[\"3\"] = tf.Variable(tf.zeros([layer_sizes[\"3\"]]), name=\"biases_3\")\n",
    "  layers[\"3\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(layers[\"2\"], weights[\"3\"]) + biases[\"3\"]), \n",
    "    keep_probs[\"3\"])\n",
    "  \n",
    "  # output layer\n",
    "  weights[\"out\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"3\"], num_labels], stddev=stddevs[\"out\"]), name=\"weights_out\")\n",
    "  biases[\"out\"] = tf.Variable(tf.zeros([num_labels]), name=\"biases_out\")\n",
    "  \n",
    "  # logit layer\n",
    "  logits = tf.matmul(layers[\"3\"], weights[\"out\"]) + biases[\"out\"]\n",
    "\n",
    "  # calculate the loss with regularization\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels), name=\"loss\")\n",
    "  \n",
    "  # learn with exponential rate decay.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  learning_rate = tf.train.exponential_decay(starting_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # train prediction\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "  # setup validation prediction step.\n",
    "  validation_layers = {}\n",
    "  validation_layers[\"1\"] = tf.nn.relu(tf.matmul(tf_valid_dataset, weights[\"1\"]) + biases[\"1\"])\n",
    "  validation_layers[\"2\"] = tf.nn.relu(tf.matmul(validation_layers[\"1\"], weights[\"2\"]) + biases[\"2\"])\n",
    "  validation_layers[\"3\"] = tf.nn.relu(tf.matmul(validation_layers[\"2\"], weights[\"3\"]) + biases[\"3\"])\n",
    "  validation_logits = tf.matmul(validation_layers[\"3\"], weights[\"out\"]) + biases[\"out\"]\n",
    "  validation_prediction = tf.nn.softmax(validation_logits)\n",
    "\n",
    "  # and setup the test prediction step.  \n",
    "  test_layers = {}\n",
    "  test_layers[\"1\"] = tf.nn.relu(tf.matmul(tf_test_dataset, weights[\"1\"]) + biases[\"1\"])\n",
    "  test_layers[\"2\"] = tf.nn.relu(tf.matmul(test_layers[\"1\"], weights[\"2\"]) + biases[\"2\"])\n",
    "  test_layers[\"3\"] = tf.nn.relu(tf.matmul(test_layers[\"2\"], weights[\"3\"]) + biases[\"3\"])\n",
    "  test_logits = tf.matmul(test_layers[\"3\"], weights[\"out\"]) + biases[\"out\"]\n",
    "  test_prediction = tf.nn.softmax(test_logits)\n",
    "  \n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "accuracy_over_time = []\n",
    "steps = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\\n\")\n",
    "\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    accuracy_over_time.append(accuracy(predictions, batch_labels))\n",
    "    steps.append(step)\n",
    "    \n",
    "    if (step % report_every == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\\n\" % accuracy(validation_prediction.eval(), valid_labels))\n",
    "  \n",
    "  print(\"  Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "  steps, accuracy_over_time = accuracy_averaged(steps, accuracy_over_time, 40)\n",
    "  plt.plot(steps, accuracy_over_time)\n",
    "  plt.xlabel(\"steps\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.show()\n",
    "\n",
    "  # Save the final model\n",
    "  model_folder = trained_models_folder + model_name\n",
    "  makedir(model_folder)\n",
    "  saver.save(session, model_folder + \"/\" + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4 Hidden Layers with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "\n",
      "Minibatch loss at step 0: 0.790982\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 48.7%\n",
      "\n",
      "Minibatch loss at step 250: 0.697695\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 49.3%\n",
      "\n",
      "Minibatch loss at step 500: 0.697990\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 49.3%\n",
      "\n",
      "Minibatch loss at step 750: 0.693416\n",
      "Minibatch accuracy: 49.2%\n",
      "Validation accuracy: 52.5%\n",
      "\n",
      "Minibatch loss at step 1000: 0.702568\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 53.3%\n",
      "\n",
      "Minibatch loss at step 1250: 0.692605\n",
      "Minibatch accuracy: 50.8%\n",
      "Validation accuracy: 49.3%\n",
      "\n",
      "Minibatch loss at step 1500: 0.698549\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 49.1%\n",
      "\n",
      "Minibatch loss at step 1750: 0.688049\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 54.5%\n",
      "\n",
      "Minibatch loss at step 2000: 0.695839\n",
      "Minibatch accuracy: 49.2%\n",
      "Validation accuracy: 54.3%\n",
      "\n",
      "Minibatch loss at step 2250: 0.683118\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 55.1%\n",
      "\n",
      "Minibatch loss at step 2500: 0.693345\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 54.9%\n",
      "\n",
      "Minibatch loss at step 2750: 0.681151\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 54.4%\n",
      "\n",
      "Minibatch loss at step 3000: 0.680753\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 56.0%\n",
      "\n",
      "Minibatch loss at step 3250: 0.669116\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 56.3%\n",
      "\n",
      "Minibatch loss at step 3500: 0.689503\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 55.4%\n",
      "\n",
      "Minibatch loss at step 3750: 0.681297\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 58.5%\n",
      "\n",
      "Minibatch loss at step 4000: 0.685744\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 57.7%\n",
      "\n",
      "Minibatch loss at step 4250: 0.638586\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 59.4%\n",
      "\n",
      "Minibatch loss at step 4500: 0.676009\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 58.4%\n",
      "\n",
      "Minibatch loss at step 4750: 0.688849\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 59.3%\n",
      "\n",
      "Minibatch loss at step 5000: 0.665535\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 58.4%\n",
      "\n",
      "Minibatch loss at step 5250: 0.657558\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 60.6%\n",
      "\n",
      "Minibatch loss at step 5500: 0.652727\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 61.7%\n",
      "\n",
      "Minibatch loss at step 5750: 0.622184\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 61.1%\n",
      "\n",
      "Minibatch loss at step 6000: 0.660931\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 63.5%\n",
      "\n",
      "Minibatch loss at step 6250: 0.626982\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 66.7%\n",
      "\n",
      "Minibatch loss at step 6500: 0.587963\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 66.9%\n",
      "\n",
      "Minibatch loss at step 6750: 0.575745\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 68.5%\n",
      "\n",
      "Minibatch loss at step 7000: 0.574898\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 67.8%\n",
      "\n",
      "Minibatch loss at step 7250: 0.641603\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 69.9%\n",
      "\n",
      "Minibatch loss at step 7500: 0.478067\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 73.0%\n",
      "\n",
      "Minibatch loss at step 7750: 0.522090\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 73.7%\n",
      "\n",
      "Minibatch loss at step 8000: 0.548582\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 71.6%\n",
      "\n",
      "Minibatch loss at step 8250: 0.502892\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 77.2%\n",
      "\n",
      "Minibatch loss at step 8500: 0.504069\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.3%\n",
      "\n",
      "Minibatch loss at step 8750: 0.447645\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.3%\n",
      "\n",
      "Minibatch loss at step 9000: 0.547097\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.8%\n",
      "\n",
      "Minibatch loss at step 9250: 0.502879\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.4%\n",
      "\n",
      "Minibatch loss at step 9500: 0.489433\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.8%\n",
      "\n",
      "Minibatch loss at step 9750: 0.417920\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 83.7%\n",
      "\n",
      "Minibatch loss at step 10000: 0.500377\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 83.4%\n",
      "\n",
      "Minibatch loss at step 10250: 0.517327\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 84.9%\n",
      "\n",
      "Minibatch loss at step 10500: 0.341069\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.6%\n",
      "\n",
      "Minibatch loss at step 10750: 0.380337\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.5%\n",
      "\n",
      "Minibatch loss at step 11000: 0.318203\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 83.0%\n",
      "\n",
      "Minibatch loss at step 11250: 0.335233\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.9%\n",
      "\n",
      "Minibatch loss at step 11500: 0.409485\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.3%\n",
      "\n",
      "Minibatch loss at step 11750: 0.448304\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 86.4%\n",
      "\n",
      "Minibatch loss at step 12000: 0.308177\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.9%\n",
      "\n",
      "Minibatch loss at step 12250: 0.346930\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.5%\n",
      "\n",
      "Minibatch loss at step 12500: 0.336638\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.5%\n",
      "\n",
      "Minibatch loss at step 12750: 0.330224\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.2%\n",
      "\n",
      "Minibatch loss at step 13000: 0.388092\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.2%\n",
      "\n",
      "Minibatch loss at step 13250: 0.406842\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 88.2%\n",
      "\n",
      "Minibatch loss at step 13500: 0.366379\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 88.5%\n",
      "\n",
      "Minibatch loss at step 13750: 0.376225\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 88.6%\n",
      "\n",
      "Minibatch loss at step 14000: 0.415873\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 87.2%\n",
      "\n",
      "Minibatch loss at step 14250: 0.363082\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.6%\n",
      "\n",
      "Minibatch loss at step 14500: 0.318668\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.5%\n",
      "\n",
      "Minibatch loss at step 14750: 0.290020\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.7%\n",
      "\n",
      "  Test accuracy: 89.2%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"4HiddenWithDropout\"\n",
    "\n",
    "batch_size = 128\n",
    "num_steps = 15000\n",
    "report_every = 250\n",
    "starting_learning_rate = 0.2\n",
    "\n",
    "layer_sizes = {\n",
    "  \"1\": 2048,\n",
    "  \"2\": 1024,\n",
    "  \"3\": 512,\n",
    "  \"4\": 64\n",
    "}\n",
    "\n",
    "stddevs = {\n",
    "  \"1\": np.sqrt(2.0 / input_size) ,\n",
    "  \"2\": np.sqrt(2.0 / layer_sizes[\"1\"]),\n",
    "  \"3\": np.sqrt(2.0 / layer_sizes[\"2\"]),\n",
    "  \"4\": np.sqrt(2.0 / layer_sizes[\"3\"]),\n",
    "  \"out\": np.sqrt(2.0 / layer_sizes[\"4\"]),\n",
    "}\n",
    "\n",
    "keep_probs = {\n",
    "  \"1\": 0.5,\n",
    "  \"2\": 0.5,\n",
    "  \"3\": 0.5,\n",
    "  \"4\": 0.5\n",
    "}\n",
    "\n",
    "weights = {}\n",
    "biases = {}\n",
    "layers = {}\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, input_size), name=\"dataset\")\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels), name=\"labels\")\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "  # first hidden layer\n",
    "  weights[\"1\"] = tf.Variable(tf.truncated_normal(\n",
    "    [input_size, layer_sizes[\"1\"]], stddev=stddevs[\"1\"]), name=\"weights_1\")\n",
    "  biases[\"1\"] = tf.Variable(tf.zeros([layer_sizes[\"1\"]]), name=\"biases_1\")\n",
    "  layers[\"1\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(tf_train_dataset, weights[\"1\"]) + biases[\"1\"]),\n",
    "    keep_probs[\"1\"])\n",
    "  \n",
    "  # second hidden layer\n",
    "  weights[\"2\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"1\"], layer_sizes[\"2\"]], stddev=stddevs[\"2\"]), name=\"weights_2\")\n",
    "  biases[\"2\"] = tf.Variable(tf.zeros([layer_sizes[\"2\"]]), name=\"biases_2\")\n",
    "  layers[\"2\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(layers[\"1\"], weights[\"2\"]) + biases[\"2\"]),\n",
    "    keep_probs[\"2\"])\n",
    "  \n",
    "  # third hidden layer\n",
    "  weights[\"3\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"2\"], layer_sizes[\"3\"]], stddev=stddevs[\"3\"]), name=\"weights_3\")\n",
    "  biases[\"3\"] = tf.Variable(tf.zeros([layer_sizes[\"3\"]]), name=\"biases_3\")\n",
    "  layers[\"3\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(layers[\"2\"], weights[\"3\"]) + biases[\"3\"]), \n",
    "    keep_probs[\"3\"])\n",
    "  \n",
    "  # fourth hidden layer\n",
    "  weights[\"4\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"3\"], layer_sizes[\"4\"]], stddev=stddevs[\"4\"]), name=\"weights_4\")\n",
    "  biases[\"4\"] = tf.Variable(tf.zeros([layer_sizes[\"4\"]]), name=\"biases_4\")\n",
    "  layers[\"4\"] = tf.nn.dropout(\n",
    "    tf.nn.relu(tf.matmul(layers[\"3\"], weights[\"4\"]) + biases[\"4\"]), \n",
    "    keep_probs[\"4\"])\n",
    "  \n",
    "  # output layer\n",
    "  weights[\"out\"] = tf.Variable(tf.truncated_normal(\n",
    "    [layer_sizes[\"4\"], num_labels], stddev=stddevs[\"out\"]), name=\"weights_out\")\n",
    "  biases[\"out\"] = tf.Variable(tf.zeros([num_labels]), name=\"biases_out\")\n",
    "  \n",
    "  # logit layer\n",
    "  logits = tf.matmul(layers[\"4\"], weights[\"out\"]) + biases[\"out\"]\n",
    "\n",
    "  # calculate the loss with regularization\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels), name=\"loss\")\n",
    "  \n",
    "  # learn with exponential rate decay.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  learning_rate = tf.train.exponential_decay(starting_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # train prediction\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "  # setup validation prediction step.\n",
    "  validation_layers = {}\n",
    "  validation_layers[\"1\"] = tf.nn.relu(tf.matmul(tf_valid_dataset, weights[\"1\"]) + biases[\"1\"])\n",
    "  validation_layers[\"2\"] = tf.nn.relu(tf.matmul(validation_layers[\"1\"], weights[\"2\"]) + biases[\"2\"])\n",
    "  validation_layers[\"3\"] = tf.nn.relu(tf.matmul(validation_layers[\"2\"], weights[\"3\"]) + biases[\"3\"])\n",
    "  validation_layers[\"4\"] = tf.nn.relu(tf.matmul(validation_layers[\"3\"], weights[\"4\"]) + biases[\"4\"])\n",
    "  validation_logits = tf.matmul(validation_layers[\"4\"], weights[\"out\"]) + biases[\"out\"]\n",
    "  validation_prediction = tf.nn.softmax(validation_logits)\n",
    "\n",
    "  # and setup the test prediction step.  \n",
    "  test_layers = {}\n",
    "  test_layers[\"1\"] = tf.nn.relu(tf.matmul(tf_test_dataset, weights[\"1\"]) + biases[\"1\"])\n",
    "  test_layers[\"2\"] = tf.nn.relu(tf.matmul(test_layers[\"1\"], weights[\"2\"]) + biases[\"2\"])\n",
    "  test_layers[\"3\"] = tf.nn.relu(tf.matmul(test_layers[\"2\"], weights[\"3\"]) + biases[\"3\"])\n",
    "  test_layers[\"4\"] = tf.nn.relu(tf.matmul(test_layers[\"3\"], weights[\"4\"]) + biases[\"4\"])\n",
    "  test_logits = tf.matmul(test_layers[\"4\"], weights[\"out\"]) + biases[\"out\"]\n",
    "  test_prediction = tf.nn.softmax(test_logits)\n",
    "  \n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "accuracy_over_time = []\n",
    "steps = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\\n\")\n",
    "\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    accuracy_over_time.append(accuracy(predictions, batch_labels))\n",
    "    steps.append(step)\n",
    "    \n",
    "    if (step % report_every == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\\n\" % accuracy(validation_prediction.eval(), valid_labels))\n",
    "  \n",
    "  print(\"  Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "  steps, accuracy_over_time = accuracy_averaged(steps, accuracy_over_time, 40)\n",
    "  plt.plot(steps, accuracy_over_time)\n",
    "  plt.xlabel(\"steps\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.show()\n",
    "\n",
    "  # Save the final model\n",
    "  model_folder = trained_models_folder + model_name\n",
    "  makedir(model_folder)\n",
    "  saver.save(session, model_folder + \"/\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
