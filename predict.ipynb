{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import face_detector\n",
    "\n",
    "image_size = 128\n",
    "pixel_depth = 255.0\n",
    "trained_models_folder = \"tf_trained\"\n",
    "\n",
    "def predict_3HiddenWithDropout(img1, img2):\n",
    "  succes1, img_raw_data1 = detector.get_face(img1)\n",
    "  if not succes1:\n",
    "    print(\"no face in pic 1\")\n",
    "    return False\n",
    "  \n",
    "  succes2, img_raw_data2 = detector.get_face(img2)\n",
    "  if not succes2:\n",
    "    print(\"no face in pic 2\")\n",
    "    return False\n",
    "  \n",
    "  image_data_1 = (np.array(img_raw_data1) - pixel_depth / 2) / pixel_depth\n",
    "  image_data_2 = (np.array(img_raw_data2) - pixel_depth / 2) / pixel_depth\n",
    "  img_1_flattened = image_data_1.reshape(image_size * image_size)\n",
    "  img_2_flattened = image_data_2.reshape(image_size * image_size)\n",
    "  \n",
    "  data = np.array([np.concatenate((img_1_flattened, img_2_flattened), axis=0)])\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    graph = tf.get_default_graph()\n",
    "    saved_model = trained_models_folder + \"/3HiddenWithDropout\"\n",
    "\n",
    "    checkpoint = tf.train.latest_checkpoint(saved_model)\n",
    "    saver = tf.train.import_meta_graph(saved_model + \"/3HiddenWithDropout.meta\")\n",
    "    saver.restore(sess, checkpoint)\n",
    "    \n",
    "    w = {}\n",
    "    w[\"1\"] = graph.get_tensor_by_name('weights_1:0')\n",
    "    w[\"2\"] = graph.get_tensor_by_name('weights_2:0')\n",
    "    w[\"3\"] = graph.get_tensor_by_name('weights_3:0')\n",
    "    w[\"out\"] = graph.get_tensor_by_name('weights_out:0')\n",
    "    \n",
    "    b = {}\n",
    "    b[\"1\"] = graph.get_tensor_by_name('biases_1:0')\n",
    "    b[\"2\"] = graph.get_tensor_by_name('biases_2:0')\n",
    "    b[\"3\"] = graph.get_tensor_by_name('biases_3:0')\n",
    "    b[\"out\"] = graph.get_tensor_by_name('biases_out:0')\n",
    "    print(w[\"1\"], b[\"1\"])\n",
    "    \n",
    "    layers = {}\n",
    "    layers[\"1\"] = tf.nn.relu(tf.matmul(tf.cast(data, tf.float32), w[\"1\"]) + b[\"1\"])\n",
    "    layers[\"2\"] = tf.nn.relu(tf.matmul(layers[\"1\"], w[\"2\"]) + b[\"2\"])\n",
    "    layers[\"3\"] = tf.nn.relu(tf.matmul(layers[\"2\"], w[\"3\"]) + b[\"3\"])\n",
    "    logits = tf.matmul(layers[\"3\"], w[\"out\"]) + b[\"out\"]\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    return prediction.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_trained/3HiddenWithDropout/3HiddenWithDropout\n",
      "Tensor(\"weights_1:0\", shape=(32768, 2048), dtype=float32_ref) Tensor(\"biases_1:0\", shape=(2048,), dtype=float32_ref)\n",
      "[[0.96807545 0.03192455]]\n"
     ]
    }
   ],
   "source": [
    "print(predict_3HiddenWithDropout(\n",
    "    \"/Users/koraygocmen/Documents/github/same-people/raw/816/0.jpg\", \n",
    "    \"/Users/koraygocmen/Documents/github/same-people/raw/816/5.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import face_detector\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"same_people_detector_v1\")\n",
    "detector = face_detector.FaceDetector(image_size=128)\n",
    "\n",
    "def are_same_people(img1, img2):\n",
    "  succes1, img_raw_data1 = detector.get_face(img1)\n",
    "  if not succes1:\n",
    "    return True, \"no face in pic 1\"\n",
    "\n",
    "  succes2, img_raw_data2 = detector.get_face(img2)\n",
    "  if not succes2:\n",
    "    return True, \"no face in pic 2\"\n",
    "\n",
    "  image_data_1 = (np.array(img_raw_data1) - pixel_depth / 2) / pixel_depth\n",
    "  image_data_2 = (np.array(img_raw_data2) - pixel_depth / 2) / pixel_depth\n",
    "  img_1_flattened = image_data_1.reshape(image_size * image_size)\n",
    "  img_2_flattened = image_data_2.reshape(image_size * image_size)\n",
    "\n",
    "  data = np.array([np.concatenate((img_1_flattened, img_2_flattened), axis=0)])\n",
    "  prediction = loaded_model.predict(data)\n",
    "  \n",
    "  same_people = None\n",
    "  if int(round(prediction[0][0])) == 1 and int(round(prediction[0][1])) == 0:\n",
    "    same_people = True\n",
    "  elif int(round(prediction[0][0])) == 0 and int(round(prediction[0][1])) == 1:\n",
    "    same_people = False\n",
    "  \n",
    "  return False, same_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, True)\n"
     ]
    }
   ],
   "source": [
    "print(are_same_people(\n",
    "  \"/Users/koraygocmen/Documents/github/same-people/raw/816/0.jpg\", \n",
    "  \"/Users/koraygocmen/Documents/github/same-people/raw/816/5.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, True)\n"
     ]
    }
   ],
   "source": [
    "print(are_same_people(\n",
    "  \"/Users/koraygocmen/Documents/github/same-people/raw/808/2.jpg\",\n",
    "  \"/Users/koraygocmen/Documents/github/same-people/raw/808/4.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, False)\n"
     ]
    }
   ],
   "source": [
    "print(are_same_people(\n",
    "  \"/Users/koraygocmen/Documents/github/same-people/raw/816/0.jpg\",\n",
    "  \"/Users/koraygocmen/Documents/github/same-people/raw/808/4.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
